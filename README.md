### [README FOR ENGLISH](qwen/README.md)
### æ€»è¿°
<details>
  <summary>ç‚¹å‡»è¿™é‡Œå±•å¼€/æŠ˜å å†…å®¹</summary>
  <ul>
    <li>ä»‹ç»æœ¬å·¥ä½œæ˜¯ <a href="https://github.com/NVIDIA/trt-samples-for-hackathon-cn/tree/master/Hackathon2023">NVIDIA TensorRT Hackathon 2023</a> çš„å‚èµ›é¢˜ç›®ï¼Œæœ¬é¡¹ç›®å°†ä½¿ç”¨TRT-LLMå®Œæˆå¯¹Qwen-7B-Chatå®ç°æ¨ç†åŠ é€Ÿã€‚</li>
    <li>åŸå§‹æ¨¡å‹ï¼šQwen-7B-Chat</li>
    <li>åŸå§‹æ¨¡å‹URLï¼š
      <ul>
        <li><a href="https://huggingface.co/Qwen/Qwen-7B-Chat">Qwen-7B-Chat ğŸ¤—</a></li>
        <li><a href="https://github.com/QwenLM/Qwen-7B">Qwen-7B-Chat Github</a></li>
      </ul>
    </li>
    <li>æ³¨ï¼šHugggingfaceçš„Qwen-7B-Chat V1.0è²Œä¼¼ä¸‹æ¶äº†ï¼Œéœ€è¦çš„å¯ä»¥ç”¨ç½‘ç›˜ä¸‹è½½ã€‚
      <ul>
        <li><a href="https://pan.baidu.com/s/1Ra4mvQcRCbkzkReFYhk3Vw?pwd=6fxh">ç™¾åº¦ç½‘ç›˜</a> æå–ç : 6fxh</li>
        <li><a href="https://mega.nz/folder/d3YH2SaJ#QSoyfqSXBmNKlpyro6lvVA">Megaç½‘ç›˜</a></li>
        <li><a href="https://www.123pan.com/s/oEqDVv-LFik.html">123pan</a> æå–ç : JAUb</li>
      </ul>
    </li>
    <li>æ³¨ï¼š2023-09-25 Huggingfaceçš„Qwen-7B-Chatå†æ¬¡ä¸Šæ¶ï¼Œä¸è¿‡è¿™æ¬¡ä¸Šæ¶çš„æ˜¯V1.1ç‰ˆï¼Œå…¶seq_lengthä»2048å˜æˆäº†8192ï¼Œå…¶ä»–å€’æ˜¯æ²¡å•¥å˜åŒ–ï¼ŒåŒæ ·å¯ä»¥å®Œç¾è¿è¡Œã€‚</li>
    <li>æ³¨ï¼š2023-09-25 Huggingfaceçš„Qwen-14-Chatä¸Šæ¶ï¼Œç»æµ‹è¯•trt-llmä»£ç å®Œç¾è¿è¡Œï¼Œåªéœ€è¦æ”¹ä¸€ä¸‹default_config.pyçš„æ–‡ä»¶è·¯å¾„å°±å¯ä»¥è¿è¡Œã€‚</li>
    <li>é€‰é¢˜ç±»å‹ï¼š2+4ï¼ˆæ³¨ï¼š2æŒ‡çš„æ˜¯TRT-LLMå®ç°æ–°æ¨¡å‹ã€‚4æŒ‡çš„æ˜¯åœ¨æ–°æ¨¡å‹ä¸Šå¯ç”¨äº†TRT-LLMç°æœ‰featureï¼‰</li>
  </ul>
</details>

### æ›´æ–°è¯´æ˜
#### 2023/12/06 æ›´æ–°
1. æ”¯æŒQwen-xxx-Chat-Int4æ¨¡å‹ç›´æ¥ç¼–è¯‘æˆTensorRT Engineã€‚
2. ä¿®å¤awqå¤šå¡qkv biaséƒ¨åˆ†æŠ¥é”™ã€‚

#### 2023/11/22 æ›´æ–°
1. æ–°å¢chatglm3-6b-32kæ¨¡å‹æ”¯æŒï¼Œchatglm3-6b-32kä¸chatglm3-6bç›¸æ¯”ä¸åŒä¹‹å¤„åœ¨äºä½ç½®ç¼–ç çš„rope_ratioä¸åŒï¼Œ[æ–‡æ¡£é“¾æ¥](./chatglm3-6b-32k/README.md)
#### 2023/11/21 æ›´æ–°
1. æ–°å¢chatglm2-6bæ¨¡å‹æ”¯æŒï¼Œç›¸æ¯”ç¤¾åŒºç‰ˆæœ¬å¢åŠ äº†tpæ”¯æŒï¼Œé€‚ç”¨äºchatglm2-6bå’Œchatglm3-6bï¼Œ[æ–‡æ¡£é“¾æ¥](./chatglm2-6b/README.md)ã€‚
2. å¾…ä¼˜åŒ–ï¼šglm2/3ä½¿ç”¨çš„æ˜¯GQAï¼Œä½†æ˜¯ç°åœ¨çš„è®¡ç®—æ–¹å¼é€€åŒ–æˆäº†MHAï¼ŒçŒœæµ‹åŸå› æ˜¯glm2å®ç°çš„æ—¶å€™gpt attention pluginè¿˜ä¸æ”¯æŒgqaï¼Œå¯ä»¥è¯´æ˜¯é—ç•™é—®é¢˜ï¼Œå¯ä»¥å‚è€ƒllama 80Bçš„å®ç°ï¼Œç›´æ¥ä½¿ç”¨GQAï¼ŒåŠ é€Ÿè®¡ç®—ã€‚
3. æ–°å¢int4-awqæ”¯æŒï¼Œç”¨äºQwen-xx-chatã€‚
#### 2023/11/16 æ›´æ–°
1. api.pyæ–°å¢function callåŠŸèƒ½ï¼ŒåŒæ—¶æ–°å¢å¤©æ°”æŸ¥è¯¢demo,ä»£ç åœ¨[qwen/client/openai_function_call.py](qwen/client/openai_function_call.py)ã€‚ï¼ˆæ³¨æ„ï¼šå¤©æ°”apiéœ€è¦è‡ªå·±å»å’Œé£å¤©æ°”ç”³è¯·ï¼Œç½‘ç«™ï¼šhttps://dev.qweather.com/ ï¼‰
- ![æµ‹è¯•æ¡ˆä¾‹1](./images/function_call_001.jpg)
- ![æµ‹è¯•æ¡ˆä¾‹2](./images/function_call_002.jpg)

#### 2023/11/09 æ›´æ–°
1. æ–°å¢int4-gptqæ”¯æŒï¼Œæ„Ÿè°¢[@Sanster](https://github.com/Sanster)çš„è´¡çŒ®ã€‚

#### 2023/10/25æ›´æ–°

1. æ›´æ–°TensorRT-LLMåº•å±‚ï¼Œä»2023å¹´7æœˆä»½æ¯”èµ›ä¸“ç”¨ç‰ˆæ›´æ–°åˆ°10æœˆä»½å‘å¸ƒçš„release/0.5.0ç‰ˆã€‚
2. æ—§çš„æ¯”èµ›ç›¸å…³æ–‡ä»¶ä»ç„¶ä¿ç•™åœ¨[release/0.1.0åˆ†æ”¯](https://github.com/Tlntin/Qwen-7B-Chat-TensorRT-LLM/tree/release/0.1.0)ï¼Œå¦‚æœéœ€è¦æ·±å…¥å­¦ä¹ å»ºè®®ç”¨mainåˆ†æ”¯ï¼Œç›®å‰è®¾å®šrelease/0.5.0ä¸ºä¸»åˆ†æ”¯ã€‚
3. å¢åŠ `TensorRT-LLMæ¥å…¥LangChainæŒ‡å—`ï¼Œ[æ–‡æ¡£é“¾æ¥](./docs/trt_llm_deploy_langchain.md)ã€‚
4. å¢åŠ `Tritonéƒ¨ç½²TensorRT-LLMæ•™ç¨‹`ï¼Œå¹¶ä¸”å¯é€‰`inflight_batching`åŠŸèƒ½ï¼Œ[æ–‡æ¡£é“¾æ¥](./docs/triton_deploy_trt-llm.md)ã€‚
5. æ”¯æŒint8-kv-cacheå’Œ`--remove_input_padding`å’Œ`--enable_context_fmha`æ¥èŠ‚çœæ˜¾å­˜ã€‚

### ä¸»è¦è´¡çŒ®

##### ä¼˜åŒ–æ•ˆæœ
- ç²¾åº¦ï¼šfp16 åŸºæœ¬å’ŒåŸç‰ˆä¸€æ ·ï¼Œint8(weight only) / int4(weight only) /int8(smooth quant) Rougeåˆ†æ•°ç•¥æœ‰æé«˜ã€‚æ€»çš„æ¥è¯´ï¼Œå’ŒåŸç‰ˆåŸºæœ¬ç›¸å·®ä¸å¤§ã€‚
- åŠ é€Ÿæ¯”ï¼šåååŠ é€Ÿæ¯”æœ€é«˜**4.57**å€ï¼Œç”ŸæˆåŠ é€Ÿæ¯”æœ€é«˜**5.56**å€ã€‚

##### è¿è¡ŒæŒ‡å—

1. å‡†å¤‡å·¥ä½œ
   - æœ‰ä¸€ä¸ªè‹±ä¼Ÿè¾¾æ˜¾å¡ï¼Œå»ºè®®12Gæ˜¾å­˜ä»¥ä¸Šï¼Œæ¨è24Gï¼ˆæ³¨ï¼š12Gæ˜¾å­˜å¯ä»¥ç”¨int4, 16Gæ˜¾å­˜å¯ä»¥ç”¨int8, 24Gæ˜¾å­˜å¯ä»¥ç”¨fp16ï¼‰ã€‚
   - éœ€è¦Linuxç³»ç»Ÿï¼ŒWSLæˆ–è®¸ä¹Ÿå¯ä»¥è¯•è¯•ã€‚
   - å·²ç»å®‰è£…äº†dockerï¼Œå¹¶ä¸”å®‰è£…äº†nvidia-dockerï¼Œ[å®‰è£…æŒ‡å—](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html)
   - éœ€è¦è¾ƒå¤§çš„ç£ç›˜ç©ºé—´ï¼Œæœ€å°‘50Gä»¥ä¸Šï¼Œæ¨è100Gã€‚
   - éœ€è¦è¾ƒå¤§çš„CPUå†…å­˜ï¼Œæœ€å°‘32Gï¼Œæ¨è64Gä»¥ä¸Šã€‚

2. æ‹‰å–æœ¬é¡¹ç›®ä»£ç 

    ```bash
    git clone https://github.com/Tlntin/Qwen-7B-Chat-TensorRT-LLM.git -b release/0.5.0
    cd Qwen-7B-Chat-TensorRT-LLM
    ```

3. ç”±äºç°åœ¨è¿˜æ²¡æœ‰ç°æˆçš„TensorRT-LLM dockeré•œåƒï¼Œéœ€è¦è‡ªå·±ç¼–è¯‘dockeré•œåƒï¼Œå¯å‚è€ƒè¯¥[æ–‡æ¡£](https://github.com/NVIDIA/TensorRT-LLM/blob/release/0.5.0/docs/source/installation.md)ï¼Œä¹Ÿå¯ä»¥ç›´æ¥ç”¨ä¸‹é¢çš„å‘½ä»¤ç›´æ¥ç¼–è¯‘ï¼ˆå·²æœ‰ç¼–è¯‘å¥½çš„é•œåƒå¯ä»¥è·³è¿‡è¯¥æ­¥éª¤ï¼‰ã€‚
    - æ‰‹åŠ¨ç¼–è¯‘
    ```bash
    # æ‹‰å–TensorRT-LLMä»“åº“
    git submodule update --init --recursive
    git lfs install
    git lfs pull
    
    # ç¼–è¯‘docker
    cd TensorRT-LLM/docker
    make release_build
    
    # ç„¶åè¿”å›åˆ°é¡¹ç›®è·¯å¾„
    cd ../..
    ```
    - å®˜æ–¹é•œåƒï¼ˆæ¨èï¼‰ï¼Œéœ€è¦æ‰‹åŠ¨å®‰è£…trt-llm pythonåŒ…ï¼Œè¯¦ç»†ä½¿ç”¨å¯ä»¥å‚è€ƒ[è¯¥æ•™ç¨‹](https://zhuanlan.zhihu.com/p/664545577)
    ```bash
    docker pull nvcr.io/nvidia/tritonserver:23.10-trtllm-python-py3
    ```
    - æ‹‰å–ç¼–è¯‘å¥½çš„é•œåƒï¼ˆä»…åœ¨RTX 3090ä¸Šé¢æµ‹è¯•ï¼Œä¸ä¿è¯å…¶ä»–æ˜¾å¡å¯ç”¨ï¼Œä¸è¿‡ç†è®ºä¸Š30ç³»/40ç³»åº”è¯¥éƒ½å¯ä»¥ï¼‰
    ```bash
    docker pull registry.cn-guangzhou.aliyuncs.com/tlntin/triton_trt_llm:v0.5.0
    docker tag registry.cn-guangzhou.aliyuncs.com/tlntin/triton_trt_llm:v0.5.0 tensorrt_llm/release
    ```

4. è¿›å…¥é¡¹ç›®ç›®å½•ï¼Œç„¶ååˆ›å»ºå¹¶å¯åŠ¨å®¹å™¨ï¼ŒåŒæ—¶å°†æœ¬åœ°`qwen`ä»£ç è·¯å¾„æ˜ å°„åˆ°`/app/tensorrt_llm/examples/qwen`è·¯å¾„ï¼Œç„¶åæ‰“å¼€8000å’Œ7860ç«¯å£çš„æ˜ å°„ï¼Œæ–¹ä¾¿è°ƒè¯•apiå’Œwebç•Œé¢ã€‚

    ```bash
    docker run --gpus all \
      --name trt_llm \
      -d \
      --ipc=host \
      --ulimit memlock=-1 \
      --restart=always \
      --ulimit stack=67108864 \
      -p 8000:8000 \
      -p 7860:7860 \
      -v ${PWD}/qwen:/app/tensorrt_llm/examples/qwen \
      tensorrt_llm/release sleep 8640000
    ```

5. ä¸‹è½½æ¨¡å‹`QWen-7B-Chat`æ¨¡å‹ï¼ˆå¯ä»¥å‚è€ƒæ€»è¿°éƒ¨åˆ†ï¼‰ï¼Œç„¶åå°†æ–‡ä»¶å¤¹é‡å‘½åä¸º`qwen_7b_chat`ï¼Œæœ€åæ”¾åˆ°`qwen/`è·¯å¾„ä¸‹å³å¯ã€‚

6. è¿›å…¥dockerå®¹å™¨é‡Œé¢çš„qwenè·¯å¾„ï¼Œå®‰è£…æä¾›çš„Pythonä¾èµ–

    ```bash
    cd /app/tensorrt_llm/examples/qwen/
    pip install -r requirements.txt
    ```

7. å°†Huggingfaceæ ¼å¼çš„æ•°æ®è½¬æˆFT(FastTransformer)éœ€è¦çš„æ•°æ®æ ¼å¼ï¼ˆéå¿…é€‰ï¼Œä¸convertç›´æ¥buildä¹Ÿæ˜¯å¯ä»¥çš„ï¼Œä¸¤ç§æ–¹å¼éƒ½å…¼å®¹ï¼Œç›´æ¥buildæ›´çœç©ºé—´ï¼Œä½†æ˜¯ä¸æ”¯æŒsmooth quant; è¿è¡Œè¯¥ä»£ç é»˜è®¤æ˜¯éœ€è¦åŠ è½½cudaç‰ˆhuggingfaceæ¨¡å‹å†è½¬æ¢ï¼Œæ‰€ä»¥ä½äº24Gæ˜¾å­˜çš„æ˜¾å¡å»ºè®®è·³è¿‡è¿™æ­¥ã€‚ï¼‰

    ```bash
    python3 hf_qwen_convert.py
    ```

8. ä¿®æ”¹ç¼–è¯‘å‚æ•°ï¼ˆå¯é€‰ï¼‰

    - é»˜è®¤ç¼–è¯‘å‚æ•°ï¼ŒåŒ…æ‹¬batch_size, max_input_len, max_new_tokens, seq_lengthéƒ½å­˜æ”¾åœ¨`default_config.py`ä¸­
    - å¯¹äº24Gæ˜¾å­˜ç”¨æˆ·ï¼Œç›´æ¥ç¼–è¯‘å³å¯ï¼Œé»˜è®¤æ˜¯fp16æ•°æ®ç±»å‹ï¼Œmax_batch_size=2
    - å¯¹äºä½æ˜¾å­˜ç”¨æˆ·ï¼Œå¯ä»¥é™ä½max_batch_size=1ï¼Œæˆ–è€…ç»§ç»­é™ä½max_input_len, max_new_tokens

9. å¼€å§‹ç¼–è¯‘ã€‚

    - å¯¹äº24Gæ˜¾å­˜ç”¨æˆ·ï¼Œå¯ä»¥ç›´æ¥ç¼–è¯‘fp16ï¼ˆæ³¨ï¼š`--remove_input_padding`å’Œ`--enable_context_fmha`ä¸ºå¯é€‰å‚æ•°ï¼Œå¯ä»¥ä¸€å®šç¨‹åº¦ä¸ŠèŠ‚çœæ˜¾å­˜ï¼‰ã€‚

    ```bash
    python3 build.py --remove_input_padding --enable_context_fmha
    ```
    
    - å¯¹äº16Gæ˜¾å­˜ç”¨æˆ·ï¼Œå¯ä»¥è¯•è¯•int8 (weight only)ã€‚

    ```bash
    python3 build.py --use_weight_only --weight_only_precision=int8
    ```
    
    - å¯¹äº12Gæ˜¾å­˜ç”¨æˆ·ï¼Œå¯ä»¥è¯•è¯•int4 (weight only)
    ```bash
    python3 build.py --use_weight_only --weight_only_precision=int4
    ```
    
    - å¯¹äº14Bæ¨¡å‹ï¼Œå¦‚æœå•å¡è£…ä¸ä¸‹ï¼Œåˆä¸æƒ³ç”¨int4/int8é‡åŒ–ï¼Œå¯ä»¥é€‰æ‹©å°è¯•tp = 2ï¼Œå³å¯ç”¨ä¸¤å¼ GPUè¿›è¡Œç¼–è¯‘ ï¼ˆæ³¨ï¼štpåŠŸèƒ½ç›®å‰åªæ”¯æŒä»Huggingfaceæ ¼å¼æ„å»ºengineï¼‰
    ```bash
    python3 build.py --world_size 2 --tp_size 2
    ```
    
10. è¯•è¿è¡Œï¼ˆå¯é€‰ï¼‰ç¼–è¯‘å®Œåï¼Œå†è¯•è·‘ä¸€ä¸‹ï¼Œè¾“å‡º`Output: "æ‚¨å¥½ï¼Œæˆ‘æ˜¯æ¥è‡ªè¾¾æ‘©é™¢çš„å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼Œæˆ‘å«é€šä¹‰åƒé—®ã€‚<|im_end|>"`è¿™è¯´æ˜æˆåŠŸã€‚

    - tp = 1ï¼ˆé»˜è®¤å•GPUï¼‰æ—¶ä½¿ç”¨pythonç›´æ¥è¿è¡Œrun.py
    ```bash
    python3 run.py
    ```

    - tp = 2ï¼ˆ2å¡ç”¨æˆ·ï¼Œæˆ–è€…æ›´å¤šGPUå¡ï¼‰æ—¶ï¼Œä½¿ç”¨`mpirun`å‘½ä»¤æ¥è¿è¡Œrun.py
    ```bash
    mpirun -n 2 --allow-run-as-root python run.py
    ```

11. éªŒè¯æ¨¡å‹ç²¾åº¦ï¼ˆå¯é€‰ï¼‰ã€‚å¯ä»¥è¯•è¯•è·‘ä¸€ä¸‹`summarize.py`ï¼Œå¯¹æ¯”ä¸€ä¸‹huggingfaceå’Œtrt-llmçš„rougeå¾—åˆ†ã€‚å¯¹äº`ç½‘ç»œä¸å¥½`çš„ç”¨æˆ·ï¼Œå¯ä»¥ä»ç½‘ç›˜ä¸‹è½½æ•°æ®é›†ï¼Œç„¶åæŒ‰ç…§ä½¿ç”¨è¯´æ˜æ“ä½œå³å¯ã€‚

     - ç™¾åº¦ç½‘ç›˜ï¼šé“¾æ¥: https://pan.baidu.com/s/1UQ01fBBELesQLMF4gP0vcg?pwd=b62q æå–ç : b62q 
     - è°·æ­Œäº‘ç›˜ï¼šhttps://drive.google.com/drive/folders/1YrSv1NNhqihPhCh6JYcz7aAR5DAuO5gU?usp=sharing
     - è·‘hugggingfaceç‰ˆ

     ```bash
     python3 summarize.py --backend=hf
     ```

     - è·‘trt-llmç‰ˆ

     ```bash
     python3 summarize.py --backend=trt_llm
     ```

     - æ³¨ï¼šå¦‚æœç”¨äº†ç½‘ç›˜çš„æ•°æ®é›†ï¼Œè§£å‹ååŠ è½½å°±éœ€è¦å¤šä¸¤ä¸ªç¯å¢ƒå˜é‡äº†ï¼Œè¿è¡Œç¤ºèŒƒå¦‚ä¸‹ï¼š

     ```bash
     HF_DATASETS_OFFLINE=1 TRANSFORMERS_OFFLINE=1 python3 summarize.py --backend=hf
     æˆ–è€…
     HF_DATASETS_OFFLINE=1 TRANSFORMERS_OFFLINE=1 python3 summarize.py --backend=trt_llm
     ```

     - ä¸€èˆ¬æ¥è¯´ï¼Œå¦‚æœtrt-llmçš„rougeåˆ†æ•°å’Œhuggingfaceå·®ä¸å¤šï¼Œç•¥ä½ä¸€äº›ï¼ˆ1ä»¥å†…ï¼‰æˆ–è€…ç•¥é«˜ä¸€äº›ï¼ˆ2ä»¥å†…ï¼‰ï¼Œåˆ™è¯´æ˜ç²¾åº¦åŸºæœ¬å¯¹é½ã€‚

12. æµ‹é‡æ¨¡å‹ååé€Ÿåº¦å’Œç”Ÿæˆé€Ÿåº¦ï¼ˆå¯é€‰ï¼‰ã€‚éœ€è¦ä¸‹è½½`ShareGPT_V3_unfiltered_cleaned_split.json`è¿™ä¸ªæ–‡ä»¶ã€‚

     - å¯ä»¥é€šè¿‡wget/æµè§ˆå™¨ç›´æ¥ä¸‹è½½ï¼Œ[ä¸‹è½½é“¾æ¥](https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered/resolve/main/ShareGPT_V3_unfiltered_cleaned_split.json)
     - ä¹Ÿå¯é€šè¿‡ç™¾åº¦ç½‘ç›˜ä¸‹è½½ï¼Œé“¾æ¥: https://pan.baidu.com/s/12rot0Lc0hc9oCb7GxBS6Ng?pwd=jps5 æå–ç : jps5
     - ä¸‹è½½ååŒæ ·æ”¾åˆ°`examples/qwen/`è·¯å¾„ä¸‹å³å¯
     - æµ‹é‡å‰ï¼Œå¦‚æœéœ€è¦æ”¹max_input_length/max_new_tokensï¼Œå¯ä»¥ç›´æ¥æ”¹`default_config.py`å³å¯ã€‚ä¸€èˆ¬ä¸æ¨èä¿®æ”¹ï¼Œå¦‚æœä¿®æ”¹äº†è¿™ä¸ªï¼Œåˆ™éœ€è¦é‡æ–°ç¼–è¯‘ä¸€æ¬¡trt-llmï¼Œä¿è¯ä¸¤è€…è¾“å…¥æ•°æ®é›†é•¿åº¦ç»Ÿä¸€ã€‚
     - æµ‹é‡huggingfaceæ¨¡å‹

     ```bash
     python3 benchmark.py --backend=hf --dataset=ShareGPT_V3_unfiltered_cleaned_split.json --hf_max_batch_size=1
     ```

     - æµ‹é‡trt-llmæ¨¡å‹ (æ³¨æ„ï¼š`--trt_max_batch_size`ä¸åº”è¯¥è¶…è¿‡buildæ—¶å€™å®šä¹‰çš„æœ€å¤§batch_sizeï¼Œå¦åˆ™ä¼šå‡ºç°å†…å­˜é”™è¯¯ã€‚)

     ```bash
     python3 benchmark.py --backend=trt_llm --dataset=ShareGPT_V3_unfiltered_cleaned_split.json --trt_max_batch_size=1
     ```

13. å°è¯•ç»ˆç«¯å¯¹è¯ï¼ˆå¯é€‰ï¼‰ã€‚è¿è¡Œä¸‹é¢çš„å‘½ä»¤ï¼Œç„¶åè¾“å…¥ä½ çš„é—®é¢˜ï¼Œç›´æ¥å›è½¦å³å¯ã€‚

     ```bash
     python3 cli_chat.py
     ```

14. éƒ¨ç½²apiï¼Œå¹¶è°ƒç”¨apiè¿›è¡Œå¯¹è¯ï¼ˆå¯é€‰ï¼‰ã€‚

      - éƒ¨ç½²api

      ```bash
      python3 api.py
      ```

      - å¦å¼€ä¸€ä¸ªç»ˆç«¯ï¼Œè¿›å…¥`qwen/client`ç›®å½•ï¼Œé‡Œé¢æœ‰4ä¸ªæ–‡ä»¶ï¼Œåˆ†åˆ«ä»£è¡¨ä¸åŒçš„è°ƒç”¨æ–¹å¼ã€‚
      - `async_client.py`ï¼Œé€šè¿‡å¼‚æ­¥çš„æ–¹å¼è°ƒç”¨apiï¼Œé€šè¿‡SSEåè®®æ¥æ”¯æŒæµå¼è¾“å‡ºã€‚
      - `normal_client.py`ï¼Œé€šè¿‡åŒæ­¥çš„æ–¹å¼è°ƒç”¨apiï¼Œä¸ºå¸¸è§„çš„HTTPåè®®ï¼ŒPostè¯·æ±‚ï¼Œä¸æ”¯æŒæµå¼è¾“å‡ºï¼Œè¯·æ±‚ä¸€æ¬¡éœ€è¦ç­‰æ¨¡å‹ç”Ÿæˆå®Œæ‰€æœ‰æ–‡å­—åï¼Œæ‰èƒ½è¿”å›ã€‚
      - `openai_normal_client.py`ï¼Œé€šè¿‡`openai`æ¨¡å—ç›´æ¥è°ƒç”¨è‡ªå·±éƒ¨ç½²çš„apiï¼Œè¯¥ç¤ºä¾‹ä¸ºéæµå¼è°ƒç”¨ï¼Œè¯·æ±‚ä¸€æ¬¡éœ€è¦ç­‰æ¨¡å‹ç”Ÿæˆå®Œæ‰€æœ‰æ–‡å­—åï¼Œæ‰èƒ½è¿”å›ã€‚ã€‚
      - `openai_stream_client.py`ï¼Œé€šè¿‡`openai`æ¨¡å—ç›´æ¥è°ƒç”¨è‡ªå·±éƒ¨ç½²çš„apiï¼Œè¯¥ç¤ºä¾‹ä¸ºæµå¼è°ƒç”¨ã€‚
      - æ³¨æ„ï¼šéœ€è¦`pydantic`æ¨¡å—ç‰ˆæœ¬>=2.3.2ï¼Œå¦åˆ™å°†ä¼šå‡ºç°`ChatCompletionResponse' object has no attribute 'model_dump_json'`æŠ¥é”™ï¼Œå‚è€ƒ[issue](https://github.com/Tlntin/Qwen-7B-Chat-TensorRT-LLM/issues/27)

15. å°è¯•ç½‘é¡µå¯¹è¯ï¼ˆå¯é€‰ï¼Œéœ€è¦å…ˆéƒ¨ç½²apiï¼‰ã€‚è¿è¡Œä¸‹é¢çš„å‘½ä»¤ï¼Œç„¶åæ‰“å¼€æœ¬åœ°æµè§ˆå™¨ï¼Œè®¿é—®ï¼š[http://127.0.0.1:7860](http://127.0.0.1:7860) å³å¯

     ```bash
     python3 web_demo.py
     ```
     - é»˜è®¤é…ç½®çš„web_demo.pyå¦‚ä¸‹ï¼š
     ```python
     demo.queue().launch(share=False, inbrowser=True)
     ```
     - å¦‚æœæ˜¯æœåŠ¡å™¨è¿è¡Œï¼Œå»ºè®®æ”¹æˆè¿™æ ·
     ```python
     demo.queue().launch(server_name="0.0.0.0", share=False, inbrowser=False) 
     ```
     - web_demoå‚æ•°è¯´æ˜
         - `share=True`: ä»£è¡¨å°†ç½‘ç«™ç©¿é€åˆ°å…¬ç½‘ï¼Œä¼šè‡ªåŠ¨ç”¨ä¸€ä¸ªéšæœºçš„ä¸´æ—¶å…¬ç½‘åŸŸåï¼Œæœ‰æ•ˆæœŸ3å¤©ï¼Œä¸è¿‡è¿™ä¸ªé€‰é¡¹å¯èƒ½ä¸å¤ªå®‰å…¨ï¼Œæœ‰å¯èƒ½é€ æˆæœåŠ¡å™¨è¢«æ”»å‡»ï¼Œä¸å»ºè®®æ‰“å¼€ã€‚
         - `inbrowser=True`: éƒ¨ç½²æœåŠ¡åï¼Œè‡ªåŠ¨æ‰“å¼€æµè§ˆå™¨ï¼Œå¦‚æœæ˜¯æœ¬æœºï¼Œå¯ä»¥æ‰“å¼€ã€‚å¦‚æœæ˜¯æœåŠ¡å™¨ï¼Œä¸å»ºè®®æ‰“å¼€ï¼Œå› ä¸ºæœåŠ¡å™¨ä¹Ÿæ²¡æœ‰è°·æ­Œæµè§ˆå™¨ç»™ä½ æ‰“å¼€ã€‚
         - `server_name="0.0.0.0"`: å…è®¸ä»»æ„ipè®¿é—®ï¼Œé€‚åˆæœåŠ¡å™¨ï¼Œç„¶åä½ åªéœ€è¦è¾“å…¥`http://[ä½ çš„ip]: 7860`å°±èƒ½çœ‹åˆ°ç½‘é¡µäº†ï¼Œå¦‚æœä¸å¼€è¿™ä¸ªé€‰æ‹©ï¼Œé»˜è®¤åªèƒ½éƒ¨ç½²çš„é‚£å°æœºå™¨æ‰èƒ½è®¿é—®ã€‚
         - `share=False`ï¼šä»…å±€åŸŸç½‘/æˆ–è€…å…¬ç½‘ipè®¿é—®ï¼Œä¸ä¼šç”Ÿæˆå…¬ç½‘åŸŸåã€‚
         - `inbrowser=False`ï¼š éƒ¨ç½²åä¸æ‰“å¼€æµè§ˆå™¨ï¼Œé€‚åˆæœåŠ¡å™¨ã€‚

16. web_demoè¿è¡Œæ•ˆæœï¼ˆæµ‹è¯•å¹³å°ï¼šRTX 4080, qwen-7b-chat, int4 weight only)

https://github.com/Tlntin/Qwen-7B-Chat-TensorRT-LLM/assets/28218658/940c1ed1-14f7-45f6-bf13-67c8f289c956


##### è¿è¡ŒæŒ‡å—ï¼ˆSmooth Quantç¯‡ï¼‰
1. å‰6èŠ‚å’Œä¸Šé¢ä¸€æ ·ï¼Œå‚è€ƒä¸Šé¢è¿è¡Œå°±è¡Œã€‚æ³¨æ„ï¼šè¿è¡ŒSmooth Quantéœ€è¦å°†huggingfaceæ¨¡å‹å®Œå…¨åŠ è½½åˆ°GPUé‡Œé¢ï¼Œç”¨äºæ„å»ºint8æ ‡å®šæ•°æ®é›†ï¼Œæ‰€ä»¥éœ€è¦æå‰ç¡®ä¿ä½ çš„æ˜¾å­˜å¤Ÿå¤§ï¼Œèƒ½å¤Ÿå®Œå…¨åŠ è½½æ•´ä¸ªæ¨¡å‹ã€‚

2. å°†Huggingfaceæ ¼å¼çš„æ•°æ®è½¬æˆFT(FastTransformer)éœ€è¦çš„æ•°æ®æ ¼å¼
    ```bash
    python3 hf_qwen_convert.py --smoothquant=0.5
    ```


3. å¼€å§‹ç¼–è¯‘trt_engine
    - æ™®é€šç‰ˆ
    ```bash
    python3 build.py --use_smooth_quant
    ```

    - å‡çº§ç‰ˆï¼ˆç†è®ºä¸Šè¿è¡Œé€Ÿåº¦æ›´å¿«ï¼Œæ¨ç†æ•ˆæœæ›´å¥½ï¼Œå¼ºçƒˆæ¨èï¼‰
    ```bash
    python3 build.py --use_smooth_quant --per_token --per_channel
    ```
4. ç¼–è¯‘å®Œæˆï¼Œrun/summarize/benchmarkç­‰ç­‰éƒ½å’Œä¸Šé¢çš„æ˜¯ä¸€æ ·çš„äº†ã€‚

##### è¿è¡ŒæŒ‡å—ï¼ˆint8-kv-cacheç¯‡ï¼‰
1. å‰6èŠ‚å’Œä¸Šé¢ä¸€æ ·ï¼Œå‚è€ƒä¸Šé¢è¿è¡Œå°±è¡Œã€‚æ³¨æ„ï¼šè¿è¡Œint8-kv-cacheéœ€è¦å°†huggingfaceæ¨¡å‹å®Œå…¨åŠ è½½åˆ°GPUé‡Œé¢ï¼Œç”¨äºæ„å»ºint8æ ‡å®šæ•°æ®é›†ï¼Œæ‰€ä»¥éœ€è¦æå‰ç¡®ä¿ä½ çš„æ˜¾å­˜å¤Ÿå¤§ï¼Œèƒ½å¤Ÿå®Œå…¨åŠ è½½æ•´ä¸ªæ¨¡å‹ã€‚
2. å°†Huggingfaceæ ¼å¼çš„æ•°æ®è½¬æˆFT(FastTransformer)éœ€è¦çš„æ•°æ®æ ¼å¼ã€‚
```bash
python3 hf_qwen_convert.py --calibrate-kv-cache
```
3. ç¼–è¯‘int8 weight only + int8-kv-cache
```bash
python3 build.py --use_weight_only --weight_only_precision=int8 --int8_kv_cache
```
##### è¿è¡ŒæŒ‡å—ï¼ˆint4-gptqç¯‡ï¼‰
1. éœ€è¦å®‰è£…[auto-gptq](https://github.com/PanQiWei/AutoGPTQ)æ¨¡å—ï¼Œå¹¶ä¸”å‡çº§transformersæ¨¡å—ç‰ˆæœ¬ï¼Œæœ€ä½è¦æ±‚4.32.0ã€‚ï¼ˆæ³¨ï¼šå®‰è£…å®Œæ¨¡å—åå¯èƒ½ä¼šæç¤ºtensorrt_llmä¸å…¶ä»–æ¨¡å—ç‰ˆæœ¬ä¸å…¼å®¹ï¼Œå¯ä»¥å¿½ç•¥è¯¥è­¦å‘Šï¼‰
```bash
pip install auto-gptq optimum
pip install transformers -U
```
2. æ‰‹åŠ¨è·å–æ ‡å®šæƒé‡ï¼ˆå¯é€‰ï¼‰
- è½¬æƒé‡è·å–scaleç›¸å…³ä¿¡æ¯ï¼Œé»˜è®¤ä½¿ç”¨GPUè¿›è¡Œæ ¡å‡†ï¼Œéœ€è¦èƒ½å¤Ÿå®Œæ•´åŠ è½½æ¨¡å‹ã€‚ï¼ˆæ³¨ï¼šå¯¹äºQwen-7B-Chat V1.0ï¼Œå¯ä»¥åŠ ä¸Š`--device=cpu`æ¥å°è¯•ç”¨cpuæ ‡å®šï¼Œä½†æ˜¯æ—¶é—´ä¼šå¾ˆé•¿ï¼‰
```bash
python3 gptq_convert.py
```
- ç¼–è¯‘TensorRT-LLM Engine
```bash
python build.py --use_weight_only \
                --weight_only_precision int4_gptq \
                --per_group
```
- å¦‚æœæƒ³è¦èŠ‚çœæ˜¾å­˜ï¼ˆæ³¨ï¼šåªèƒ½ç”¨äºå•batchï¼‰ï¼Œå¯ä»¥è¯•è¯•åŠ ä¸Šè¿™ä¿©å‚æ•°æ¥ç¼–è¯‘Engine
```bash
python build.py --use_weight_only \
                --weight_only_precision int4_gptq \
                --per_group \
                --remove_input_padding \
                --enable_context_fmha
```
3. ä½¿ç”¨å®˜æ–¹int4æƒé‡ï¼Œä¾‹å¦‚Qwen-xx-Chat-Int4æ¨¡å‹ï¼ˆæ¨èï¼‰
- ç¼–è¯‘æ¨¡å‹ï¼Œæ³¨æ„è®¾ç½®hfæ¨¡å‹è·¯å¾„å’Œ`--quant_ckpt_path`é‡åŒ–åæƒé‡è·¯å¾„å‡è®¾ç½®ä¸ºåŒä¸€ä¸ªè·¯å¾„ï¼Œä¸‹é¢æ˜¯1.8bæ¨¡å‹çš„ç¤ºä¾‹ï¼ˆå…¶ä»–æ¨¡å‹ä¹Ÿæ˜¯ä¸€æ ·æ“ä½œï¼‰
```bash
python build.py --use_weight_only \
                --weight_only_precision int4_gptq \
                --per_group \
                --hf_model_dir Qwen-1_8B-Chat-Int4 \
                --quant_ckpt_path Qwen-1_8B-Chat-Int4
```
- è¿è¡Œæ¨¡å‹ï¼Œè¿™é‡Œéœ€è¦æŒ‡å®šä¸€ä¸‹tokenizerè·¯å¾„
```bash
python3 run.py --tokenizer_dir=Qwen-1_8B-Chat-Int4
```

##### è¿è¡ŒæŒ‡å—ï¼ˆint4-awqç¯‡ï¼‰
1. éœ€è¦ä¸‹è½½å¹¶å®‰è£…[nvidia-ammo](https://developer.nvidia.com/downloads/assets/cuda/files/nvidia-ammo/nvidia_ammo-0.3.0.tar.gz)æ¨¡å—ï¼Œä¸‹é¢æ˜¯ä¸€ä¸ªå®‰è£…ä»£ç å‚è€ƒï¼Œæ³¨æ„ä¸è¦å®‰è£…cudaç‰ˆï¼Œè€Œæ˜¯å®‰è£…é€šç”¨ç‰ˆï¼Œå¦åˆ™ä¼šæœ‰bugã€‚
```bash
pip install nvidia_ammo-0.3.0-cp310-cp310-linux_x86_64.whl
```
2. ä¿®æ”¹ammoä»£ç ï¼ŒåŠ ä¸Šqwenæ”¯æŒï¼ˆä¸åŠ ä¸Šä¼šæŠ¥é”™ï¼‰ï¼Œä¸‹é¢æ˜¯ä¸€ä¸ªç®€å•çš„å‚è€ƒæ¡ˆä¾‹ï¼š
- å…ˆåœ¨vscodeï¼Œä»»æ„å†™ä¸€ä¸ªpythonæ–‡ä»¶ï¼Œå¯¼å…¥ä¸‹é¢çš„å‡½æ•°
```python
from tensorrt_llm.models.quantized.ammo import quantize_and_export
```
- ç„¶åcontrl + é¼ æ ‡å·¦æŒ‰é”®ï¼Œå•å‡»`quantize_and_export`å‡½æ•°ï¼ŒæŸ¥çœ‹å®ƒçš„å†…éƒ¨å®ç°ã€‚
- åœ¨ä¸‹é¢çš„ifåˆ¤æ–­é‡Œé¢ï¼ŒåŠ ä¸Šä¸‹é¢è¿™æ®µä»£ç ï¼Œç”¨æ¥æ”¯æŒQwen
```bash
elif "QWen" in model_cls_name:
    model_type = "qwen"
```
- ä¿®æ”¹åé•¿è¿™æ ·ï¼š
```bash
model_cls_name = type(model).__name__
if "Llama" in model_cls_name:
    model_type = "llama"
elif "GPTJ" in model_cls_name:
    model_type = "gptj"
elif "GPT2" in model_cls_name:
    model_type = "gpt2"
elif "QWen" in model_cls_name:
    model_type = "qwen"
elif "Falcon" in model_cls_name or "RW" in model_cls_name:
    model_type = "falcon"
else:
    raise NotImplementedError(
        f"Deploying quantized model {model_cls_name} is not supported")
```
3. è¿è¡Œint4-awqé‡åŒ–ä»£ç ï¼Œå¯¼å‡ºæ ¡å‡†æƒé‡ã€‚
```bash
python3 quantize.py --export_path ./qwen_7b_4bit_gs128_awq.pt
```
4. è¿è¡Œbuild.pyï¼Œç”¨äºæ„å»ºTensorRT-LLM Engineã€‚
```bash
python build.py --use_weight_only \
                --weight_only_precision int4_awq \
                --per_group \
                --quant_ckpt_path ./qwen_7b_4bit_gs128_awq.pt
```
5. å¦‚æœæƒ³è¦èŠ‚çœæ˜¾å­˜ï¼ˆæ³¨ï¼šåªèƒ½ç”¨äºå•batchï¼‰ï¼Œå¯ä»¥è¯•è¯•åŠ ä¸Šè¿™ä¿©å‚æ•°æ¥ç¼–è¯‘Engine
```bash
python build.py --use_weight_only \
                --weight_only_precision int4_awq \
                --per_group \
                --remove_input_padding \
                --enable_context_fmha \
                --quant_ckpt_path ./qwen_7b_4bit_gs128_awq.pt
```
### ä¸»è¦å¼€å‘å·¥ä½œ

##### å¼€å‘å·¥ä½œçš„éš¾ç‚¹

1. huggingfaceè½¬llm-trtæ¯”è¾ƒç¹çã€‚
    - ç›®å‰åªèƒ½è‚‰çœ¼è§‚å¯Ÿå·²æœ‰æˆåŠŸæ¡ˆä¾‹ï¼Œä¾‹å¦‚å‚è€ƒchatglm/llama, é€šè¿‡debug huggingfaceç‰ˆå’Œè§‚å¯Ÿtrt-llmç‰ˆï¼Œäº†è§£æ•´ä½“æ€è·¯ã€‚
    - ç„¶åè§‚å¯Ÿqwenå’Œchatglm/llamaçš„å·®å¼‚ï¼Œæ‹¿è¿™ä¸¤ä¸ªæ¡ˆä¾‹åšé­”æ”¹ã€‚
    - é€šè¿‡å¯¹æ¯”ä»£ç ï¼Œå‘ç°examplesä¸‹é¢çš„chatglm-6bçš„rope embeddingå’Œqwenç±»ä¼¼ï¼Œæ‰€ä»¥chatglm-6bçš„rope embeddingçš„trtå®ç°å¯ä»¥ä½œä¸ºå‚è€ƒé¡¹ã€‚
    - ç§»æ¤æ—¶å‘ç°,ropeæå‰ç®—å¥½äº†weightsï¼Œç„¶ååˆ†å‰²æˆäº†ä¸¤ä¸ªcos_embeddingå’Œsin_embeddingã€‚ä¸ºç¡®ä¿è¯¥æ–¹æ¡ˆå¯è¡Œï¼Œäºæ˜¯åœ¨huggingfaceç‰ˆçš„qwenä¸­å®ç°äº†ç±»ä¼¼ç»“æ„ï¼Œå¯¹æ¯”rope_coså’Œrope_simçš„è¾“å‡ºç»“æœï¼Œä»¥åŠå¯¹åº”sumå€¼ï¼Œå‘ç°è¯¥æ“ä½œå¯è¡Œï¼Œäºæ˜¯å°†å…¶ç§»æ¤åˆ°äº†qwen trt-llmä¸­ã€‚
    - ä¸è¿‡éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œqwençš„dimå’Œmax_position_dimå’Œchatglm-6bä¸ä¸€æ ·ï¼ŒåŠ ä¸Šchatglm-6b trt-llmçš„ropeçš„inv_freqåšäº†ä¸€å®šçº¦åˆ†ï¼Œå¯¼è‡´çœ‹èµ·æ¥æ¯”è¾ƒå¥‡æ€ªï¼Œæ‰€ä»¥åç»­æˆ‘ä»¬ç›´æ¥ä½¿ç”¨äº†çš„qwenåŸç‰ˆçš„inv_freqè®¡ç®—ï¼Œä»¥åŠqwenåŸç‰ˆçš„apply_rotary_pos_embæ–¹æ³•ã€‚
    - æ•´ä½“ä»£ç é­”æ”¹è‡ªllama, attention/ropeå‚è€ƒäº†chatglm-6bã€‚

2. é¦–æ¬¡è¿è¡ŒæŠ¥æ˜¾å­˜åˆ†é…é”™è¯¯ã€‚
    - åœ¨å…¶é™„è¿‘æ’å…¥å¯ç”¨æ˜¾å­˜å’Œéœ€è¦åˆ†é…çš„æ˜¾å­˜ä»£ç ï¼Œå‘ç°æ˜¯æ˜¾å­˜ä¸å¤Ÿ, å°†max_batch_sizeä»é»˜è®¤çš„8æ”¹æˆ2åè§£å†³ã€‚

3. fp16ä¸‹ï¼Œæ¨¡å‹çš„logitsæ— æ³•å¯¹é½ã€‚
    - é€šè¿‡é˜…è¯»[docs/2023-05-19-how-to-debug.md](https://github.com/Tlntin/Qwen-7B-Chat-TensorRT-LLM/blob/main/tensorrt_llm_july-release-v1/docs/2023-05-19-how-to-debug.md)æ–‡æ¡£ï¼ŒåŸºæœ¬æŒæ¡çš„debugèƒ½åŠ›ï¼Œç„¶åæŒ‰ç…§ä»£ç è¿è¡Œé¡ºåºï¼Œä»å¤–åˆ°å†…debugï¼Œæ‰¾åˆ°è¯¯å·®æ‰€åœ¨å±‚ã€‚
    - é¦–å…ˆæˆ‘ä»¬å¯¹æ¯”äº†wteå’Œropeè¾“å‡ºï¼ŒåŸºæœ¬ç¡®å®šè¿™ä¸¤ä¸ªlayeræ²¡æœ‰é—®é¢˜ã€‚
    - ç„¶åæˆ‘ä»¬æ‰“å°äº†qwen_blockçš„æ¯å±‚è¾“å…¥ï¼Œå…¶ä¸­ç¬¬ä¸€ä¸ªlayerçš„è¾“å…¥hidden_statesæ­£å¸¸ï¼Œåç»­è¯¯å·®é€æ­¥å¢åŠ ï¼Œæ‰€ä»¥åˆæ­¥ç¡®å®šè¯¯å·®åœ¨QwenBlockè¿™ä¸ªç±»ä¸­ã€‚
    - ç”±äºattentionä½¿ç”¨äº†ropeç›¸å…³è®¡ç®—+gpt attention_layerï¼Œè¿™é‡Œå‡ºé—®é¢˜çš„å¯èƒ½æ€§è¾ƒå¤§ï¼Œäºæ˜¯æˆ‘ä»¬åœ¨QwenBlockä¸­çš„attentionè®¡ç®—é‡Œé¢åŠ å…¥è°ƒè¯•æ“ä½œï¼Œæ‰“å°å…¶è¾“å…¥ä¸è¾“å‡ºç»“æœï¼Œå¹¶å’Œpytorchåšæ•°å€¼å¯¹æ¯”ï¼ˆä¸»è¦å¯¹æ¯”mean, sumæ•°å€¼ï¼‰ã€‚ç»å¯¹æ¯”å‘ç°QwenBlockçš„attentionè¾“å…¥sumè¯¯å·®åœ¨0.2ä»¥å†…ï¼ŒåŸºæœ¬okï¼Œä½†æ˜¯å…¶è¾“å‡ºè¯¯å·®å¾ˆå¤§ï¼Œæ‰€ä»¥éœ€è¦è¿›ä¸€æ­¥å®šä½ã€‚
    - ç”±äºQwenAttentionä¸­é‡‡ç”¨äº†ropeç›¸å…³è®¡ç®—+gpt attention pluginçš„æ–¹å¼ç»„åˆè€Œæˆï¼Œè€Œpluginè°ƒè¯•ç›¸å¯¹å›°éš¾ï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦è¿›ä¸€æ­¥æµ‹è¯•gpt attention pluginçš„è¾“å…¥è¾“å‡ºã€‚è‹¥è¾“å…¥æ­£å¸¸ï¼Œè¾“å‡ºå¼‚å¸¸ï¼Œåˆ™gpt attention pluginå¼‚å¸¸ï¼Œåä¹‹ï¼Œåˆ™å¯èƒ½æ˜¯pluginä¹‹å‰çš„layeræœ‰é—®é¢˜ã€‚
    - åœ¨gpt attention pluginå¤„æ‰“å°å‘ç°è¾“å…¥ç»“æœæ— æ³•å¯¹é½ï¼Œäºæ˜¯é€å±‚å¯¹æ¯”QwenAttention forwardè¿‡ç¨‹ï¼Œæœ€ç»ˆå®šä½åˆ°ä¸‹é¢è¿™æ®µä»£ç è¾“å‡ºå¼‚å¸¸ã€‚
    ```bash
    qkv = concat([query, key, value], dim=2)
    qkv = qkv.view(
        concat([shape(qkv, 0),
                shape(qkv, 1),
                self.hidden_size * 3])
    )
    ```
    - åœ¨ç»è¿‡2/3å¤©è°ƒè¯•åï¼Œå‘ç°ä¸concatæ— ç“œï¼Œæ˜¯pluginå†…éƒ¨å†æ¬¡è®¡ç®—äº†ä¸€æ¬¡rope,å¯¼è‡´qkvç»“æœå¼‚å¸¸ï¼Œå°†`tensorrt_llm.functional.gpt_attention`è¾“å…¥çš„`rotary_embedding_dim`è®¾ç½®ä¸º0åï¼Œè¯¥é—®é¢˜å¾—åˆ°è§£å†³ã€‚ä¸è¿‡æœ€ç»ˆè¾“å‡ºè¿˜æ˜¯æœ‰é—®é¢˜ï¼Œç»è¿‡å¯¹æ¯”å‘ç°attentionè¾“å‡ºå·²ç»æ­£å¸¸ï¼Œä½†æ˜¯QwenBlocké‡Œé¢çš„self.mlpè¾“å‡ºå¼‚å¸¸ï¼Œéœ€è¦è¿›ä¸€æ­¥å¯¹æ¯”ã€‚
    - ç»å¯¹æ¯”å‘ç°åŸæ¥çš„`GateMLP` forwardå‡½æ•°ä¸­ï¼Œæ˜¯å¯¹ç¬¬ä¸€ä¸ªlayerè¾“å‡ºåšäº†siluæ¿€æ´»ï¼Œè€Œqwenæ˜¯å¯¹ç¬¬äºŒä¸ªlayerçš„è¾“å‡ºåšsiluæ¿€æ´»ï¼Œä¸¤è€…å­˜åœ¨åŒºåˆ«ï¼Œæ‰€ä»¥æˆ‘ä»¬åˆé‡æ–°å»ºäº†ä¸€ä¸ª`QwenMLP`ç±»ç”¨æ¥å®ç°åŸç‰ˆçš„è®¡ç®—è¿‡ç¨‹ã€‚
    - ç»è¿‡ä¸Šè¿°ä¼˜åŒ–ï¼Œç»å¯¹æ¯”è¾“å‡ºçš„logitså¹³å‡è¯¯å·®å¤§æ¦‚åœ¨0.002å·¦å³ï¼ŒåŸºæœ¬å®Œæˆäº†ç²¾åº¦å¯¹é½ã€‚

4. trt-llmè¾“å‡ºç»“æœå’Œpytorchä¸ä¸€è‡´ã€‚
    - æ­¤æ—¶æ•´ä¸ªæ¨¡å‹çš„è®¡ç®—è¿‡ç¨‹å·²ç»æ²¡æœ‰é—®é¢˜ï¼Œä¹Ÿå¯¹æ¯”äº†ä¸åŒstepçš„è¾“å‡ºï¼Œéƒ½æ˜¯å¯ä»¥å¯¹ä¸Šçš„ï¼Œä½†æ˜¯è¾“å‡ºçš„ç»“æœå’Œpytorchè¿˜æ˜¯æœ‰åŒºåˆ«ï¼š
    ```bash
    input:
    """
    <|im_start|>system
    You are a helpful assistant.<|im_end|>
    <|im_start|>user
    ä½ å¥½ï¼Œè¯·é—®ä½ å«ä»€ä¹ˆï¼Ÿ<|im_end|>
    <|im_start|>assistant
    """
	
    pytorch output: 
    """
    æ‚¨å¥½ï¼Œæˆ‘æ˜¯æ¥è‡ªè¾¾æ‘©é™¢çš„å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼Œæˆ‘å«é€šä¹‰åƒé—®ã€‚<|im_end|>
    """
	
    trt-llm output: 
    """
    æ‚¨å¥½ï¼Œæˆ‘æ˜¯æ¥è‡ªè¾¾æ‘©é™¢çš„å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼Œæˆ‘å«é€šä¹‰åƒé—®ã€‚<|im_end|>
    <|im_start|>assistant
	
    å¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡ã€‚<|im_end|>
    <|endoftext|> Ñ€ĞµÑˆĞ¸Ğ» ĞºÑƒĞ¿Ğ¸Ñ‚ÑŒ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ½Ğ¾ÑƒÑ‚Ğ±ÑƒĞº, Ğ½Ğ¾ Ğ½Ğµ Ğ¼Ğ¾Ğ³Ñƒ Ğ²Ñ‹Ğ±Ñ€Ğ°Ñ‚ÑŒ Ğ¼ĞµĞ¶Ğ´Ñƒ Ñ‚Ñ€ĞµĞ¼Ñ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸ÑĞ¼Ğ¸."
    """
    ```
    - ç»è¿‡å¯¹æ¯”å‘ç°æ˜¯å› ä¸ºsampling configæ²¡æœ‰å¯¹é½ï¼Œè§‚å¯Ÿäº†pytorchåŸç‰ˆçš„åå¤„ç†é€»è¾‘ï¼Œå‘ç°å…¶å°†`tokenizer.im_start_id, tokenizer.im_end_id`è®¾ç½®ä¸ºäº†end of tokenï¼Œè€ƒè™‘åˆ°trt-llmåªèƒ½è®¾ç½®ä¸€ä¸ªend of token, è€Œåœ¨è¾“å‡ºæ—¶<|im_end|>å…ˆäº<|im_start|>ï¼Œæ‰€ä»¥æˆ‘ä»¬å°†å°†`EOS_TOKEN`ä¿®æ”¹ä¸º`tokenizer.im_end_id`å¯¹åº”çš„æ•°å­—ã€‚å¹¶å°†top-p, top-kè®¾ç½®åŸpytorchç‰ˆ`generation_config.json`ä¸­å¯¹åº”çš„æ•°å­—ã€‚
    - æ”¹å®Œåæˆ‘ä»¬å‘ç°ç»“å°¾å­˜åœ¨å¤§é‡é‡å¤`<|im_end|>`ï¼ˆ`PAD`å’Œ`EOS_TOKEN`è§£ç å¯¹åº”çš„å†…å®¹ï¼‰ï¼Œè¿™ä¸ªä¸»è¦æ˜¯å‰æœŸpast_key_valueèµ‹å€¼çš„æ—¶å€™æ˜¯é»˜è®¤ç»™äº†æœ€é•¿çš„é•¿åº¦`max_input_length+max_output_length`ï¼Œæˆ‘ä»¬åœ¨debug run.pyä¸­å‘ç°decodeçš„stepå¹¶ä¸ä¸€å®šè¾“å‡ºæœ€å¤§é•¿åº¦ï¼Œè€Œæ˜¯ç»å¸¸ä¸­é€”é€€å‡ºå¾ªç¯ã€‚æ‰€ä»¥æˆ‘ä»¬å†³å®šå°†é€€å‡ºæ—¶çš„stepè¿”å›ï¼Œå¦‚æœæ²¡æœ‰ä¸­é€”é€€å‡ºå°±è¿”å›æœ€å¤§max_output_length, è¿™æ ·å°±å¯ä»¥çŸ¥é“æ¨¡å‹çœŸå®ç”Ÿæˆçš„é•¿åº¦ã€‚ä»¥æœ€å¤§è¾“å…¥é•¿åº¦+çœŸå®ç”Ÿæˆé•¿åº¦åšæˆªæ–­ï¼Œç„¶åå†ç”¨tokenizerè§£ç ï¼Œå°±å¯ä»¥å¾—åˆ°æœ€ç»ˆè¾“å‡ºç»“æœäº†ã€‚
    ```bash
    Input: 
    """
    <|im_start|>system
    You are a helpful assistant.<|im_end|>
    <|im_start|>user
    ä½ å¥½ï¼Œè¯·é—®ä½ å«ä»€ä¹ˆï¼Ÿ<|im_end|>
    <|im_start|>assistant
    """
	
    Output
    """
    æ‚¨å¥½ï¼Œæˆ‘æ˜¯æ¥è‡ªè¾¾æ‘©é™¢çš„å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼Œæˆ‘å«é€šä¹‰åƒé—®ã€‚<|im_end|>
    """
    ```
	- æ­¤æ—¶è¾“å‡ºç»“æœå’Œpytorchå®Œå…¨ä¸€è‡´ã€‚
5. è¿è¡Œ`summarize.py`æ— è¾“å‡ºã€‚
    - ç”±äºæˆ‘ä»¬é€‰æ‹©qwen-chat-7bæ˜¯ä¸€ä¸ªchatæ¨¡å‹ï¼Œæ— æ³•ç›´æ¥è¾“å…¥ä¸€æ®µæ–‡æœ¬åšæ€»ç»“ï¼Œéœ€è¦å†™ä¸€ä¸ªä¸“é—¨çš„promptï¼ˆæç¤ºè¯­ï¼‰æ¥è®©æ¨¡å‹åšè¿™ä¸ªæ€»ç»“çš„å·¥ä½œã€‚
    - äºæ˜¯æˆ‘ä»¬å°†åŸç‰ˆçš„`make_context`ç§»æ¤è¿‡æ¥ï¼Œå¹¶è®¾ç½®ä¸“é—¨çš„`system_prompt`è®©æ¨¡å‹æ ¹æ®ç”¨æˆ·è¾“å…¥ç›´æ¥åšæ€»ç»“ï¼Œè¿™æ ·å°†åŸå§‹è¾“å…¥åŠ å·¥åå†è¾“å‡ºç»“æœï¼Œä½¿å¾—æ¨¡å‹æœ‰äº†æ€»ç»“èƒ½åŠ›ã€‚


    - è‡³æ­¤ï¼Œåœ¨trt-llmä¸Šæ”¯æŒqwenæ¨¡å‹çš„åŸºç¡€å·¥ä½œå·²ç»åšå®Œ

##### å¼€å‘ä¸­çš„äº®ç‚¹
1. å®Œæ•´æ”¯æŒåŸç‰ˆçš„lognå’Œntkï¼ˆè¿™ä¿©å‚æ•°æ˜¯ç”¨äºå¢å¼ºæ¨¡å‹é•¿è¾“å…¥çš„ç”Ÿæˆæ•ˆæœï¼Œè¿™é‡Œçš„é•¿è¾“å…¥æŒ‡çš„æ˜¯è¾“å…¥é•¿åº¦å¤§äº2048å°äº8192ï¼‰ã€‚ä¸è¿‡ç”±äºtrt-llmçš„æŸäº›bugï¼Œå¯¼è‡´è¾“å…¥é•¿åº¦>2048æ—¶ï¼Œå®é™…è¾“å‡ºä¼šå¾ˆçŸ­ç”šè‡³ä¸ºç©ºï¼Œè¯¦è§[issue](https://github.com/NVIDIA/trt-samples-for-hackathon-cn/issues/90)ï¼ŒåŠ ä¸Šropeæ”¾gpt attention pluginé‡Œé¢è®¡ç®—æ›´å¿«ï¼Œæ‰€ä»¥æˆ‘ä»¬lognæ³¨é‡Šæ‰äº†ã€‚
2. æ”¯æŒ`RotaryEmbedding`ï¼Œå¹¶ä¸”åœ¨input_len > 2048æ—¶å¼€å¯ntkç›¸å…³è®¡ç®—ã€‚
3. æ”¯æŒè‡ªå¸¦çš„`gpt_attention_plugin`ä¸`gemm_plugin`ä¸¤ä¸ªpluginã€‚
4. æ–°å¢æ”¯æŒrmsnorm pluginï¼Œåœ¨profileè¿‡ç¨‹ä¸­å‘ç°åŸç”Ÿçš„rmsnormåœ¨åº•å±‚æ˜¯ç”±5ä¸ªopç»„æˆï¼Œkernel launchå æ¯”ä¸¥é‡ï¼Œå¹¶ä¸”ä¸­é—´æ•°æ®ä¼ é€’ä¹Ÿæ¶ˆè€—æ—¶é—´ï¼Œä¸€æ¬¡rmsnormè®¡ç®—å¤§æ¦‚è€—æ—¶0.022msï¼Œå› æ­¤é€šè¿‡cudaçš„æ–¹å¼å®ç°äº†rmsnormpluginï¼Œå‡å°‘kernellaunchï¼ŒåŠ å¿«è®¡ç®—ï¼Œæœ€ç»ˆä¼˜åŒ–åä¸€æ¬¡rmsnormçš„è®¡ç®—æ—¶é—´é™ä½åˆ°äº†0.0057msã€‚

<p align="center">
  <div style="display: flex; flex-direction: column; align-items: center;">
    <picture>
      <source media="(prefers-color-scheme: dark)" srcset="./images/tensorrt_rmsnorm_op.jpeg">
      <p align="center">
      <img src="./images/tensorrt_rmsnorm_op.jpeg" width="80%">
      </p>
    </picture>
    <picture>
      <source media="(prefers-color-scheme: dark)" srcset="./images/rmsnormplugin.jpeg">
      <p align="center">
      <img src="./images/rmsnormplugin.jpeg" width="80%">
      </p>
    </picture>
  </div>
  <br>
  <p align="center">
  <em> RmsnormPlugin performance comparison (test on fp16) </em>
  </p>
</p>

5. ä½¿ç”¨gpt attention pluginå†…ç½®çš„ropeè®¡ç®—æ–¹æ³•ï¼Œå‚è€ƒglmï¼Œå¼€å§‹ä¹Ÿæ˜¯åœ¨gpt attention pluginå¤–é¢è®¡ç®—çš„ropeï¼ŒåŒæ ·profileå‘ç°attentionéƒ¨åˆ†è®¡ç®—kernelè¾ƒå¤šï¼Œå•æ¬¡è®¡ç®—è€—æ—¶å¤§æ¦‚åœ¨0.11msï¼Œå› æ­¤å°è¯•ä½¿ç”¨gpt attention pluginå†…ç½®çš„ropeï¼Œä¼˜åŒ–åä¸€æ¬¡attentionçš„è®¡ç®—å¤§æ¦‚åœ¨0.017msã€‚

<p align="center">
  <div style="display: flex; flex-direction: column; align-items: center;">
    <picture>
      <source media="(prefers-color-scheme: dark)" srcset="./images/rope_outside.jpeg">
      <p align="center">
      <img src="./images/rope_outside.jpeg" width="80%">
      </p>
    </picture>
    <picture>
      <source media="(prefers-color-scheme: dark)" srcset="./images/rope_inside.jpeg">
      <p align="center">
      <img src="./images/rope_inside.jpeg" width="80%">
      </p>
    </picture>
  </div>
  <br>
  <p align="center">
  <em> RmsnormPlugin performance comparison (test on fp16) </em>
  </p>
</p>

6. åŒæ—¶å°†`layernorm_plugin`é­”æ”¹æˆ`rmsnorm_plugin`ä»¥æ”¯æŒsmooth_quanté‡åŒ–æŠ€æœ¯ï¼Œå¹¶ä¸”å®é™…æµ‹è¯•RmsNorm Pluginä¹Ÿå¯ä»¥ç»™fp16å’Œint8/int4 (wight only)å¸¦æ¥ä¸é”™çš„æå‡ã€‚
7. åŒæ—¶æ”¯æŒqwen baseå’Œchatæ¨¡å‹
8. æ”¯æŒfp16 / int8 (weight only) / int4 (weight only), ç†è®ºä¸Šæœ€ä½åªéœ€è¦8Gæ¶ˆè´¹çº§æ˜¾å¡å°±èƒ½è¿è¡Œã€‚
9. æ”¯æŒSmooth Quant int8é‡åŒ–ã€‚
10. æ”¯æŒåœ¨ç»ˆç«¯å¯¹è¯å’Œä½¿ç”¨gradioæ„å»ºçš„ç½‘é¡µåº”ç”¨ä¸­å¯¹è¯ï¼Œæ”¯æŒæµå¼è¾“å‡ºã€‚
11. æ”¯æŒfastapiéƒ¨ç½²ï¼Œæ”¯æŒsseåè®®æ¥å®ç°æµå¼è¾“å‡ºï¼ŒåŒæ—¶å…¼å®¹OpenAIçš„apiè¯·æ±‚ã€‚

### å¼€å‘ä¸ä¼˜åŒ–è¿‡ç¨‹

è¿™ä¸€éƒ¨åˆ†æ˜¯æŠ¥å‘Šçš„ä¸»ä½“ã€‚è¯·æŠŠè‡ªå·±å‡å®šä¸ºè€å¸ˆï¼Œä¸º TensorRT æˆ– TensorRT-LLM çš„åˆå­¦è€…è®²è¿°å¦‚ä½•ä»åŸå§‹æ¨¡å‹å‡ºå‘ï¼Œç»è¿‡ä¸€ç³»åˆ—å¼€å‘æ­¥éª¤ï¼Œå¾—åˆ°ä¼˜åŒ–åçš„ TensorRT æˆ– TensorRT-LLM æ¨¡å‹ã€‚æˆ–è€…ä½ æ˜¯å¦‚ä½•ä¸€æ­¥æ­¥é€šè¿‡ä¿®æ”¹å“ªäº›æ¨¡å—æ·»åŠ äº†æ–°featureçš„ã€‚

å»ºè®®ï¼š

- åˆ†æ­¥éª¤è®²æ¸…æ¥šå¼€å‘è¿‡ç¨‹
- æœ€å¥½èƒ½ä»‹ç»ä¸ºä»€ä¹ˆéœ€è¦æŸä¸ªç‰¹åˆ«æ­¥éª¤ï¼Œé€šè¿‡è¿™ä¸ªç‰¹åˆ«æ­¥éª¤è§£å†³äº†ä»€ä¹ˆé—®é¢˜
  - æ¯”å¦‚ï¼Œé€šè¿‡Nsight Systemsç»˜åˆ¶timelineåšäº†æ€§èƒ½åˆ†æï¼Œå‘ç°attentionæ—¶é—´å æ¯”é«˜ä¸”æœ‰ä¼˜åŒ–ç©ºé—´ï¼ˆè´´å›¾å±•ç¤ºåˆ†æè¿‡ç¨‹ï¼‰ï¼Œæ‰€ä»¥å†³å®šè¦å†™pluginã€‚ç„¶åä»‹ç»pluginçš„è®¾è®¡ä¸å®ç°ï¼Œå¹¶åœ¨timelineä¸Šæ˜¾ç¤ºattentionè¿™ä¸€éƒ¨åˆ†çš„æ€§èƒ½æ”¹è¿›ã€‚
1. è·‘ä¸€ä¸‹`examples/gpt`çš„ä»£ç ï¼Œäº†è§£ä¸€ä¸‹trt-llmçš„åŸºæœ¬æµç¨‹ã€‚

2. è¯»`QWen-7B-Chat`çš„Readmeä¿¡æ¯ï¼ŒåŸºæœ¬äº†è§£å®ƒæ˜¯ä¸€ä¸ª`decoder onlyæ¨¡å‹`ï¼Œå¹¶ä¸”æ¨¡å‹ç»“æ„ç±»llamaã€‚

3. å°†`examples/llama`å¤åˆ¶ä¸€ä»½ï¼Œç„¶åé‡å‘½åä¸º`examples/qwen`,å°†é‡Œé¢çš„æ¨¡å‹å¸¦`llama`çš„å…¨éƒ¨æ›¿æ¢ä¸º`qwen`ã€‚

4. è¿è¡Œ`build.py`æ—¶ï¼Œå‘ç°è°ƒç”¨äº†`weight.py`ï¼Œè€Œllamaé¡¹ç›®é‡Œé¢çš„`weight.py`é‡Œé¢æœ‰ä¸€ä¸ª`load_from_meta_llama`å‡½æ•°ï¼Œå‡½æ•°é‡Œé¢æœ‰ä¸€ä¸ª`tensorrt_llm.models.LLaMAForCausalLM`ï¼Œé‡Œé¢å®šä¹‰äº†æ•´ä¸ªtrtçš„æ¨¡å‹ç»“æ„ã€‚æˆ‘ä»¬ç”¨vscodeè¿›å…¥å…¶ä¸­ï¼Œå°†é‡Œé¢çš„`LLaMAForCausalLM`å¤åˆ¶å‡ºæ¥ï¼Œç„¶åæ–°å»ºäº†ä¸€ä¸ªmode.py,å°†å†…å®¹ç²˜è´´è¿›å»ã€‚åŒæ ·ï¼Œå°†é‡Œé¢çš„æ¨¡å‹å¸¦`llama`çš„å…¨éƒ¨æ›¿æ¢ä¸º`qwen`

5. ç„¶åæˆ‘ä»¬å°±å¼€å§‹æ”¹æœ¬é¡¹ç›®çš„`weight.py`çš„`load_from_meta_qwen`å‡½æ•°ï¼Œå°†huggingfaceé‡Œé¢çš„æƒé‡åç§°å’Œtrtçš„æƒé‡åç§°é€æ­¥å¯¹é½ã€‚ç„¶åæˆ‘ä»¬è¿è¡Œäº†ä¸€ä¸‹build.pyï¼Œå‘ç°å¯ä»¥ç¼–è¯‘é€šè¿‡ï¼Œä½†æ˜¯è¿è¡Œ`run.py`ç»“æœä¸å¯¹ã€‚

6. æˆ‘ä»¬é€šè¿‡è‚‰çœ¼è§‚å¯Ÿæ¨¡å‹ç»“æ„ï¼Œå‘ç°trtç‰ˆå°‘äº†ä¸€ä¸ª`RotaryEmbedding`ï¼Œè¿™ä¸ªè¯¥å¦‚ä½•å®ç°äº†ï¼Ÿè§‚å¯Ÿäº†ä¸€ä¸‹`examples/`ç›®å½•ä¸‹é¢çš„å…¶ä»–é¡¹ç›®ï¼Œçªç„¶å‘ç°é‡Œé¢çš„`chatglm6b`æœ‰ç±»ä¼¼çš„ç»“æ„ï¼Œä¸è¿‡ä»–å´åˆ†æˆäº†`position_embedding_cos`å’Œ`position_embedding_sin`ä¸¤ä¸ªæ™®é€šçš„embeddingã€‚æˆ‘ä»¬å¤§æ¦‚çŸ¥é“å®ƒæˆ–è®¸æ˜¯ä¸€ä¸ªæ–°çš„å®ç°æ–¹å¼ï¼Œä½†æ˜¯åŠŸèƒ½å’ŒåŸç‰ˆä¸€æ ·ã€‚é€šè¿‡è§‚å¯Ÿï¼Œæˆ‘ä»¬å‘ç°å…¶ropeæƒé‡æ˜¯åœ¨weight.pyé‡Œé¢ç”¨numpyæ‰‹æ“ç›´æ¥å¯¼å…¥çš„ã€‚å¯¼å…¥ä»£ç å¦‚ä¸‹ï¼š

   - chatglm6b/hf_chatglm6b_convert.py

   ```python
   nMaxSL = 2048
   inv_freq = 10**(-1 / 16 * np.arange(0, 64, 2, dtype=np.float32))
   valueTable = np.matmul(
       np.arange(nMaxSL, dtype=np.float32).reshape(-1, 1),
       np.concatenate([inv_freq, inv_freq],
                      axis=0).reshape(1, -1)).reshape(nMaxSL,
                                                      len(inv_freq) * 2)
   np.cos(valueTable).astype(storage_type).tofile(saved_dir /
                                                  "model.cosTable.weight.bin")
   np.sin(valueTable).astype(storage_type).tofile(saved_dir /
                                                  "model.sinTable.weight.bin")
   print("Save model.cosTable.weight.bin")
   print("Save model.sinTable.weight.bin")
   ```

   - chatglm6b/weight.py

   ```bash
   chatglm6bModel.position_embedding_cos.weight.value = (fromfile(
       dir_path, 'model.cosTable.weight.bin',
       [n_positions, n_embd // n_head // 2]))
   chatglm6bModel.position_embedding_sin.weight.value = (fromfile(
       dir_path, 'model.sinTable.weight.bin',
       [n_positions, n_embd // n_head // 2]))
   ```

   - ç»è¿‡å’ŒåŸç‰ˆChatGLM-6bè¿›è¡Œå¯¹æ¯”ï¼Œå¤§æ¦‚çŸ¥é“äº†2048æ˜¯åŸç‰ˆçš„æœ€å¤§è¾“å…¥é•¿åº¦ï¼Œ64æ˜¯ä»–çš„per_head_dim//2
   - è€Œqwené‡Œé¢çš„apply_ropeæ—¶çš„è®¡ç®—å’Œchatglmç•¥æœ‰å·®å¼‚ï¼Œå¹¶ä¸”qwençš„æœ€å¤§è¾“å…¥é•¿åº¦æ˜¯8192ï¼Œè¿™äº›éœ€è¦ç•¥ä½œä¿®æ”¹ã€‚
   - ä¿®æ”¹å®Œååˆ©ç”¨debug_modeå°†å¯¹åº”çš„æ•°å€¼æ‰“å°å‡ºæ¥ï¼Œä¸åŸç‰ˆè¿›è¡Œå¯¹æ¯”ï¼Œå‘ç°åŸºæœ¬ä¸€è‡´ã€‚

7. å†æ¬¡é€šè¿‡é€šè¿‡è‚‰çœ¼è§‚å¯Ÿæ¨¡å‹ç»“æ„ï¼Œå‘ç°åŸæ¨¡å‹Attentionä¸­è¿˜æœ‰lognä»¥åŠntkçš„è®¡ç®—ï¼Œå†å¢åŠ è¿™ä¸¤ç»“æ„åï¼Œå†æ¬¡åšäº†ä¸€æ¬¡ç¼–è¯‘ï¼Œå¯ä»¥æ­£å¸¸ç¼–è¯‘ã€‚

8. ç„¶åå°±æ˜¯åšfp16å¯¹é½äº†ï¼Œå‚è€ƒ`å¼€å‘å·¥ä½œçš„éš¾ç‚¹`ä¸­å…³äº`fp16ä¸‹ï¼Œæ¨¡å‹çš„logitsæ— æ³•å¯¹é½`éƒ¨åˆ†å³å¯ã€‚

9. åœ¨fp16å¯¹é½ï¼Œå¹¶ä¸”run.py/summarize.pyéƒ½æ­£å¸¸åï¼Œæˆ‘ä»¬å°±å¼€å§‹å°è¯•å®ç°weight only in8/int4ï¼Œæˆ‘ä»¬å…ˆç›´æ¥è¿è¡Œ `--use_weight_only --weight_only_precision=int8`ï¼Œç¼–è¯‘æˆåŠŸåï¼Œå†æ¬¡è¿è¡Œrun.py/summarize.pyï¼Œå‘ç°éƒ½æ­£å¸¸ã€‚int4ä¹Ÿé‡å¤è¯¥æ“ä½œï¼Œå‘ç°è¿˜æ˜¯æ­£å¸¸ï¼Œè¯´æ˜weight only in8/int4é€‚é…æˆåŠŸã€‚

10. weight only é‡åŒ–å®Œæˆåæˆ‘ä»¬å¼€å§‹å¯¹æ¨¡å‹ç»“æ„è¿›è¡Œåˆ†æï¼ŒæŸ¥çœ‹å“ªäº›æ“ä½œåœ¨åº•å±‚æ¯”è¾ƒè€—æ—¶ï¼Œå‘ç°å…¶ä¸­rmsnormæ¯”è¾ƒçç¢ï¼Œkernellaunchä»¥åŠkernelé—´äº¤äº’è€—æ—¶ä¸¥é‡ï¼Œæ‰€ä»¥æå‡ºä½¿ç”¨cudaç¼–å†™rmsnorm pluginï¼ŒåŠ é€Ÿè®¡ç®—ï¼ŒRmsNormç›¸å¯¹LayerNormæ¥è¯´ï¼Œå°±æ˜¯å°‘äº†ä¸€ä¸ªå‡å‡å€¼æ“ä½œï¼Œå¹¶ä¸”æ²¡æœ‰biasï¼Œæ‰€ä»¥æˆ‘ä»¬å…ˆæ‹·è´äº†ä¸€ä»½layerNormçš„kernelã€‚

    - æ‹·è´æ“ä½œã€‚

    ```bash
    cd cpp/tensorrt_llm/kernels
    cp layernormKernels.cu rmsnormKernels.cu
    cp layernormKernels.h rmsnormKernels.h
    ```

    - æ‹·è´å®Œåæˆ‘ä»¬å°†é‡Œé¢çš„mean/biaså»æ‰ï¼Œå¹¶å°†layernormå…³é”®è¯æ¢æˆrmsnormçš„å…³é”®è¯ã€‚åŒæ—¶æˆ‘ä»¬å‘ç°layerNormçš„.cuæ–‡ä»¶é‡Œé¢æœ‰ä¸ª`USE_DIFF_OF_SQUARES`ï¼Œè¿™ä¸ªå€¼ä¸ºTureæ—¶æ˜¯ç®—æ–¹å·®ï¼Œä¸ºFalseæ—¶ç®—å¹³å‡å€¼ã€‚ç”±äºæˆ‘ä»¬ä¸éœ€è¦å¹³å‡å€¼ï¼Œæ‰€ä»¥è¿™ä¸ªæ•°å€¼å¸¸ä¸ºTrueï¼Œæ‰€ä»¥æˆ‘ä»¬å°†ä¸ºTrueçš„éƒ¨åˆ†ä¿ç•™ï¼Œä¸ºFasleçš„éƒ¨ä½åˆ é™¤ï¼Œå¹¶ä¸”åˆ é™¤äº†è¿™ä¸ªå˜é‡ã€‚
    - åŒç†æˆ‘ä»¬å¯¹pluginsç›®å½•ä¸‹é¢çš„layerNormQuantåšäº†åŒæ ·çš„æ“ä½œã€‚

    ```bash
    cd cpp/tensorrt_llm/plugins
    cp layernormPlugin/* rmsnormPlugin/
    cp layernormQuantizationPlugin/* rmsnormQuantizationPlugin/
    ```

    - åŒæ ·å’Œä¸Šé¢ä¸€æ ·åšæ›¿æ¢ï¼Œå»biasï¼Œå»meanï¼Œå»`USE_DIFF_OF_SQUARES`ï¼ˆå»é™¤è¿™ä¸ªéœ€è¦å¿½ç•¥å¤§å°å†™ï¼Œæœ‰çš„æ˜¯å°å†™ï¼‰ï¼Œæœ€ç»ˆå®Œæˆpluginçš„ç¼–å†™ï¼Œå¹¶ä¸”ç²¾åº¦éªŒè¯æ²¡æœ‰é—®é¢˜ã€‚

11. å‚è€ƒ[æ•™ç¨‹](https://www.http5.cn/index.php/archives/30/)ï¼Œæˆ‘ä»¬é‡æ–°ç¼–è¯‘äº†TensorRT-LLMï¼Œå¹¶ä¸”åŠ è½½äº†è‡ªå®šä¹‰çš„`Rmsnorm`å’Œ`RmsnormQuantization`æ’ä»¶ï¼Œè¿è¡Œæµ‹è¯•ï¼Œå‘ç°ç»“æœæ­£å¸¸ï¼Œrmsnorm pluginé€‚é…æˆåŠŸã€‚

12. åœ¨åˆ†æè¿‡ç¨‹ä¸­åŒæ ·å‘ç°attentionè®¡ç®—è¿‡ç¨‹æ¶‰åŠçš„kernelè¾ƒå¤šï¼Œå¹¶ä¸”å’¨è¯¢å¯¼å¸ˆåæ˜ç™½gpt attention pluginä¹Ÿæ”¯æŒropeçš„è®¡ç®—ï¼Œä½†æ˜¯ç°åœ¨æˆ‘ä»¬æ˜¯æ”¾åœ¨å¤–é¢åšçš„è®¡ç®—å¯¼è‡´é™„å¸¦äº†å¤§é‡çš„kernelï¼Œå› æ­¤æˆ‘ä»¬æŠŠå¤–é¢çš„ropeè®¡ç®—æµç¨‹åˆ é™¤ï¼Œåœ¨gpt attebtion pluginä¸­è®¾ç½®æ­£ç¡®çš„rotary_embedding_dimå‚æ•°ï¼Œå……åˆ†åˆ©ç”¨tensorrtæœ¬èº«çš„èƒ½åŠ›ï¼Œæµ‹è¯•åå‘ç°ç”Ÿæˆç»“æœæ­£ç¡®ï¼Œè¯´æ˜qwenæ¨¡å‹å¯ä»¥ä½¿ç”¨gpt attention pluginå†…ç½®çš„ropeè®¡ç®—æ–¹æ³•ï¼Œropeå†…ç½®è®¡ç®—æ–¹æ³•é€‚é…æˆåŠŸã€‚

13. ä»¥ä¸Šå·¥ä½œåšå®Œåæˆ‘ä»¬åšäº†ç»Ÿä¸€æµ‹è¯•ï¼ŒåŒ…æ‹¬int8/int4 wight onlyï¼Œæµ‹è¯•ç»“æœè¡¨æ˜rougeåˆ†æ•°åŸºæœ¬å’Œä¹‹å‰ä¸€æ ·å¹¶ä¸”ç¼–è¯‘Engineé€Ÿåº¦å¤§å¹…åº¦æå‡ï¼Œè€Œä¸”è¿è¡Œsummarizeçš„é€Ÿåº¦ä¹Ÿè¿›ä¸€æ­¥æé«˜ï¼ˆå¤§æ¦‚åŠ é€Ÿ1.5ç§’ï¼‰ã€‚

14. é€‚é…å®Œåï¼Œå‘ç°è¿˜æœ‰ä¸€ä¸ªsmooth_quanté‡åŒ–ï¼Œå¯ä»¥é™ä½æ˜¾å­˜ï¼Œæé«˜æ¨ç†é€Ÿåº¦ã€‚ä¸è¿‡é—®äº†å¯¼å¸ˆï¼Œè¯´ç›®å‰åªæœ‰gpté€‚é…äº†ï¼Œåç»­å¯èƒ½é€‚é…bloomå’Œllamaï¼Œæ‰€ä»¥æˆ‘ä»¬å‚è€ƒäº†gptçš„ä»£ç ï¼Œæ–°å¢äº†ä¸€ä¸ª`hf_qwen_convert.py`æ–‡ä»¶ï¼Œç”¨äºå°†huggingfaceçš„æƒé‡å¯¼å‡ºåˆ°FT(FastTransformer)æ ¼å¼çš„æ–‡ä»¶ã€‚åŒæ—¶æˆ‘ä»¬å°†gpt/weight.pyé‡Œé¢çš„`load_from_ft`æ‹·è´åˆ°qwen/weight.pyï¼Œå¹¶æ ¹æ®æˆ‘ä»¬å¯¼å‡ºçš„æƒé‡æ–‡ä»¶ä¿®æ”¹è¿›è¡Œäº†ç®€å•ä¿®æ”¹ï¼Œç„¶åå†å°†build.pyé‡Œé¢é»˜è®¤åŠ è½½å‡½æ•°ä»`load_from_hf_qwen`æ¢æˆ `load_from_ft`,ä¸è¿‡å½“å¼€å‘è€…æ²¡æœ‰å¯¼å‡ºFTæƒé‡çš„æ—¶å€™ï¼Œè¿˜æ˜¯ä¼šè‡ªåŠ¨åŠ è½½`load_from_hf_qwen`æ¥ç”Ÿæˆengineã€‚

15. åœ¨ç”¨äº†æ–°çš„`load_from_ft`æ–¹æ³•åï¼Œæˆ‘ä»¬åˆè¿è¡Œäº†ä¸€æ¬¡run.pyå’Œsummarize.pyï¼Œå‘ç°è¾“å‡ºç»“æœå¼‚å¸¸ï¼Œç»è¿‡å¯¹examples/gptè¿›è¡Œè°ƒè¯•ï¼Œå‘ç°qwençš„attentionæƒé‡å’Œgptçš„attentionæƒé‡shapeé¡ºåºç•¥æœ‰ä¸åŒã€‚ä¸ºäº†æ›´å¥½çš„å¯¹æ¯”å·®å¼‚ï¼Œæˆ‘ä»¬å°†`load_from_ft`çš„åŠ è½½æƒé‡çš„ä»£ç ç²˜è´´åˆ°`load_from_hf_qwen`ï¼Œç„¶åä¸€ä¸ªä¸ªå˜é‡å¯¹æ¯”å…¶shapeä»¥åŠvalueå€¼ï¼Œå¯¹æ¯”å‘ç°`load_from_hf_qwen`ä¸­ï¼Œéweight_onlyé‡åŒ–ï¼Œåˆ™æƒé‡ç›´æ¥èµ‹å€¼ï¼Œå¦åˆ™éœ€è¦å¤šä¸€ä¸ªè½¬ç½®æ“ä½œã€‚ç»è¿‡ä¸€è½®ä¿®æ”¹ï¼Œ`load_from_ft`çš„fp16ç»ˆäºæ­£å¸¸ã€‚ç„¶åæˆ‘ä»¬åˆé¡ºä¾¿ç¼–è¯‘äº†weight_onlyçš„int8/int4ï¼Œå‘ç°ä¹ŸåŒæ ·æ­£å¸¸ã€‚

16. å›åˆ°smooth quanté‡åŒ–è¿™é‡Œï¼Œå‚è€ƒexample/gptçš„smooth quantè¿‡ç¨‹ï¼Œæˆ‘ä»¬åœ¨`hf_qwen_convert.py`é‡Œé¢åŒæ ·åŠ äº†`--smoothquant`é€‰é¡¹ã€‚é€šè¿‡è°ƒè¯•`example/gpt/hf_gpt_convert.py`æ–‡ä»¶ï¼Œè§‚å¯Ÿå®ƒçš„`smooth_gpt_model`å‡½æ•°çš„è®¡ç®—æ–¹æ³•ä»¥åŠå‚æ•°çš„shapeï¼Œä¸è¿‡ä»–å®ƒmlpåªæœ‰ä¸€ä¸ªfc1, è¯¥layeræ­£å¥½å¯¹åº”qwen mlpçš„w1/w2 layerï¼Œè€Œä¸”w1/w2å…±äº«ä¸€ä¸ªè¾“å…¥ï¼Œç›¸å½“äºfc1æ‹†æˆäº†ä¸¤ä»½ï¼Œå…¶ä¸­ä¸€ä»½è®¡ç®—åä¼šç»è¿‡siluæ¿€æ´»å±‚ã€‚æˆ‘ä»¬å‘ç°example/gpté‡Œé¢çš„hf_gpt_convert.pyæ–‡ä»¶é‡Œé¢æœ‰è°ƒç”¨`from smoothquant import capture_activation_range, smooth_gemm`å’Œ`from utils.convert import split_and_save_weight`ï¼Œé€šè¿‡è°ƒè¯•è¿™äº›æ–‡ä»¶ï¼Œæˆ‘ä»¬å†™äº†è‡ªå·±çš„å¯¹åº”çš„å‡½æ•°ï¼Œå¹¶ä¸”æˆåŠŸå¯¼å‡ºäº†å’Œsmooth quantå¯†åˆ‡ç›¸å…³çš„int8æƒé‡ã€‚

17. å†æ¬¡è§‚å¯Ÿexample/gptçš„smooth quantè¿‡ç¨‹ï¼Œå‚è€ƒå…¶build.pyæ–‡ä»¶ï¼Œå‘ç°é‡Œé¢æœ‰ä¸€ä¸ª`from tensorrt_llm.models import smooth_quantize`è¿‡ç¨‹ï¼Œè¿™ä¸ªå‡½æ•°ä¼šå°†trt-llmåŸæœ¬çš„æ¨¡å‹ç»“æ„ç»™æ›¿æ¢æ‰ï¼Œä¸»è¦æ›¿æ¢äº†layer_norm, attention, å’Œmlpéƒ¨åˆ†ã€‚å…¶ä¸­attentionåŸºæœ¬å’Œæˆ‘ä»¬çš„qwenä¸€æ ·ï¼Œåªæ˜¯æˆ‘ä»¬æ¯”ä»–å¤šäº†logn/apply rope/ntkä¸‰ä¸ªï¼Œmlpä¹Ÿå¯ä»¥é€šè¿‡ç®€å•ä¿®æ”¹å®ç°ã€‚ä½†æ˜¯å…³äºgptçš„layer_normï¼Œæˆ‘ä»¬ç”¨çš„æ˜¯`RmsNorm`ï¼Œè¿˜å¥½ï¼Œæˆ‘ä»¬åœ¨ä¹‹å‰å·²ç»å®ç°äº†`RmsnormQuantization`æ’ä»¶ã€‚

18. åœ¨ä»£ç ä¸­æµ‹è¯•rmsnorm smoothquantçš„é€»è¾‘æ—¶ï¼Œè¿è¡Œbuild.pyç¼–è¯‘EngnieåæŠ¥äº†ä¸€ä¸ªå’Œcublasç›¸å…³çš„é”™è¯¯ï¼Œé”™è¯¯æç¤ºï¼š`terminate called after throwing an instance of 'std::runtime_error'  what():  [TensorRT-LLM Error][int8gemm Runner] Failed to initialize cutlass int8 gemm. Error: Error Internal`ã€‚é€šè¿‡å¤šæ¬¡æ’æŸ¥ï¼Œä»¥åŠç¾¤å‹çš„æé†’ï¼Œæˆ‘ä»¬å‘ç°è¿™ä¸ªä¸æ˜¯æˆ‘ä»¬pluginçš„é—®é¢˜ï¼Œè€Œæ˜¯smooth_quant_gemmè¿™ä¸ªæ’ä»¶çš„é—®é¢˜ã€‚è¯¥é—®é¢˜å¯ä»¥é€šè¿‡ä¸‹é¢çš„å•å…ƒæµ‹è¯•å¤ç°ã€‚

    ```bash
    cd tests/quantization
    python -m unittest test_smooth_quant_gemm.py TestSmoothQuantGemm.test_matmul
    ```
19. é€šè¿‡[å‚è€ƒæ•™ç¨‹](https://www.http5.cn/index.php/archives/41/)æˆ‘ä»¬é‡æ–°ç¼–è¯‘äº†Debugç‰ˆçš„TRT-LLMï¼Œå¹¶ä¸”å¯ä»¥åœ¨vscodeä¸­è°ƒè¯•TRT-LLMä»£ç ã€‚åœ¨debugä¸­ï¼Œæˆ‘ä»¬å‘ç°äº†ä¸ªåˆ«è¾ƒå¤§çš„shapeå­˜åœ¨å…±äº«æ˜¾å­˜åˆ†é…è¿‡å¤šè€Œå¯¼è‡´cublasåˆå§‹åŒ–å¤±è´¥çš„é—®é¢˜ã€‚é€šè¿‡å¢åŠ try/catchåŠŸèƒ½ï¼Œæˆ‘ä»¬è·³è¿‡äº†å¤±è´¥çš„ç­–ç•¥ã€‚ç„¶åå†æ¬¡è·‘testå‘ç°å‡ºç°äº†ä¸‹é¢çš„é”™è¯¯ï¼š
    ```bash
    terminate called after throwing an instance of 'std::runtime_error'
    what():  [TensorRT-LLM Error][int8gemm Runner] Failed to run cutlass int8 gemm. Error: Error Internal
    ```
20. ç›´è§‰å‘Šè¯‰æˆ‘ä»¬ç­–ç•¥é€‰æ‹©å™¨èƒ½è¿è¡Œçš„ä»£ç ï¼Œåˆ°æ’ä»¶è¿è¡Œé˜¶æ®µç¡®åˆå¤±è´¥åº”è¯¥æ˜¯æŸä¸ªå‚æ•°è¿‡å¤§å¯¼è‡´äº†é‡å¤è¿è¡Œï¼Œæ‰€ä»¥æˆ‘ä»¬è°ƒæ•´äº†é‡Œé¢å’Œè¿è¡Œé˜¶æ®µæœ‰å…³çš„ä¸¤ä¸ªå‚æ•°`warmup`å’Œ`runs`ï¼Œç»è¿‡å¤šæ¬¡ç¼–è¯‘ï¼Œè¿è¡Œå•å…ƒæµ‹è¯•ï¼Œå‘ç°3å’Œ10æ˜¯æ¯”è¾ƒåˆé€‚çš„æ•°å­—ï¼Œå¯ä»¥äº§ç”Ÿè¾ƒé•¿çš„æ—¥å¿—ï¼ˆè¯´æ˜èƒ½è¿è¡Œè¾ƒé•¿æ—¶é—´ï¼‰ã€‚ä½†æ˜¯æœ€ç»ˆå•å…ƒæµ‹è¯•è¿˜æ˜¯æœªèƒ½é€šè¿‡ï¼Œåé¢æˆ‘ä»¬è¿˜æ˜¯è¯•äº†ä¸€ä¸‹smooth quantç¼–è¯‘ï¼Œç»“æœå‘ç°å¯ä»¥ã€‚æ‰€ä»¥è¿™ä¸ªå•å…ƒæµ‹è¯•å¯èƒ½å¹¶ä¸é€‚åˆ24Gæ˜¾å­˜çš„A10æ¥è¿è¡Œï¼Œæˆ–è®¸æ˜¯ç»™A100è·‘çš„å‘¢ï¼Œç›¸å…³å˜æ›´å¯ä»¥é€šè¿‡[è¯¥commit](https://github.com/Tlntin/Qwen-7B-Chat-TensorRT-LLM/commit/0667e03b726a18a9a52e8242ddaf517f90c0e16f)æŸ¥çœ‹ï¼Œæ­¤æ—¶smooth_quantå¯ä»¥ç¼–è¯‘ä¸è¿è¡Œï¼Œä½†æ˜¯ç»“æœå¹¶ä¸å¯¹ï¼Œéœ€è¦è¿›ä¸€æ­¥æ ¡å‡†ä»£ç ã€‚
21. é€šè¿‡é€è¡Œå¯¹æ¯”gpt2çš„smooth quantè¿‡ç¨‹ï¼Œæˆ‘ä»¬å‘ç°éœ€è¦smoothçš„å‡ ä¸ªlayerçš„weight shapeä¸­ï¼Œqwenå’Œgptæ˜¯è½¬ç½®å…³ç³»ã€‚æ‰€ä»¥å¯¼è‡´æˆ‘ä»¬åœ¨`capture_activation_range`å’Œ`smooth_qwen_model`è¿™ä¸¤ä¸ªå‡½æ•°ä¸­ï¼Œå…³äº`w`çš„ç»´åº¦è¦å’Œgptä¸ä¸€æ ·ï¼Œgptæ˜¯dim=0,æˆ‘ä»¬å¾—æ”¹æˆdim=1ã€‚åŒæ—¶åœ¨`split_and_save_weight`è¿™ä¸ªå‡½æ•°è°ƒç”¨å‰ï¼Œéœ€è¦å°†ä¸Šé¢å‡ ä¸ªç‰¹æ®Šlayeråˆ©ç”¨`transpose_weights`å‡½æ•°å°†å…¶è½¬æˆgptçš„æ ¼å¼ï¼Œè¿™æ ·æˆ‘ä»¬å°±å¯ä»¥å¤ç”¨å¯¹åº”çš„smooth quant int8çš„ç›¸å…³å‡½æ•°`generate_int8`å’Œ`write_int8`äº†ã€‚åŒæ—¶æˆ‘ä»¬å†æ¬¡debugäº†weight.py,ç¡®ä¿å½¢çŠ¶ç±»å‹å’Œgptå®Œå…¨ä¸€æ ·ã€‚é‡æ–°build smooth quantçš„ engeneåï¼Œæˆ‘ä»¬å‘ç°run/smmarizeå‡å®Œå…¨æ­£å¸¸ã€‚

### ä¼˜åŒ–æ•ˆæœ

è¿™ä¸€éƒ¨åˆ†ä»‹ç»ä½ çš„å·¥ä½œåœ¨äº‘ä¸»æœºä¸Šçš„è¿è¡Œæ•ˆæœã€‚å¦‚æœæ˜¯ä¼˜åŒ–æ¨¡å‹ï¼Œéœ€è¦åˆ†ä¸¤éƒ¨åˆ†è¯´æ˜ï¼š
##### ç²¾åº¦
- æŠ¥å‘Šä¸åŸå§‹æ¨¡å‹è¿›è¡Œç²¾åº¦å¯¹æ¯”æµ‹è¯•çš„ç»“æœï¼ŒéªŒè¯ç²¾åº¦è¾¾æ ‡ï¼ˆabs(rouge_diff) < 1ï¼‰ã€‚
- æµ‹è¯•å¹³å°ï¼šNVIDIA A10 (24Gæ˜¾å­˜) | TensorRT 9.0.0.1
- TRT_LLM engineç¼–è¯‘æ—¶æœ€å¤§è¾“å…¥é•¿åº¦ï¼š2048ï¼Œ æœ€å¤§æ–°å¢é•¿åº¦ï¼š2048
- HuggingFaceç‰ˆQwené‡‡ç”¨é»˜è®¤é…ç½®ï¼Œæœªå®‰è£…ï¼Œæœªå¯ç”¨FlashAttentionç›¸å…³æ¨¡å—
- æµ‹è¯•æ—¶ï¼šbeam=batch=1ï¼Œmax_new_tokens=100
- æµ‹è¯•ç»“æœï¼ˆè¯¥ç»“æœç”±`qwen/summarize.py`ç”Ÿæˆï¼‰ï¼š
```bash
HuggingFace (dtype: bf16 | total latency: 99.70530200004578 sec)
  rouge1 : 28.219357100978343
  rouge2 : 9.369007098940832
  rougeL : 19.198723845033232
  rougeLsum : 22.37342869203733

TensorRT-LLM (dtype: fp16 | total latency: 69.03318905830383 sec)
  rouge1 : 28.24200534394352
  rouge2 : 9.385498589891833
  rougeL : 19.22414575248309
  rougeLsum : 22.408209721264484

TensorRT-LLM (dtype: int8 (weight only) | total latency: 44.45594668388367 sec)
  rouge1 : 29.394430367657716
  rouge2 : 10.363250023233798
  rougeL : 19.980678095850568
  rougeLsum : 23.40562693529992

TensorRT-LLM (dtype: int4 (weight only) | total latency: 31.928248405456543 sec)
  rouge1 : 29.74935421942075
  rouge2 : 11.030115146230957
  rougeL : 19.995706951778946
  rougeLsum : 23.94860303628307

TensorRT-LLM ( dtype: int8 (smooth quant) | total latency: 40.39580488204956 sec)
TensorRT-LLM beam 0 result
  rouge1 : 29.825214246965757
  rouge2 : 11.180882972127817
  rougeL : 21.42468892994786
  rougeLsum : 24.66149284270628

```

##### æ€§èƒ½
- ä¾‹å¦‚å¯ä»¥ç”¨å›¾è¡¨å±•ç¤ºä¸åŒbatch sizeæˆ–sequence lengthä¸‹æ€§èƒ½åŠ é€Ÿæ•ˆæœï¼ˆè€ƒè™‘åˆ°å¯èƒ½æ¨¡å‹å¯èƒ½æ¯”è¾ƒå¤§ï¼Œå¯ä»¥åªç»™batch sizeä¸º1çš„æ•°æ®ï¼‰
- ä¸€èˆ¬ç”¨åŸå§‹æ¨¡å‹ä½œä¸ºbaseline
- ä¸€èˆ¬æä¾›æ¨¡å‹æ¨ç†æ—¶é—´çš„åŠ é€Ÿæ¯”å³å¯ï¼›è‹¥èƒ½æä¾›å‹åŠ›æµ‹è¯•ä¸‹çš„ååæå‡åˆ™æ›´å¥½ã€‚
- æµ‹è¯•å¹³å°ï¼šNVIDIA A10 (24Gæ˜¾å­˜) | TensorRT 9.0.0.1 | tensorrt-llm 0.1.3
- HuggingFaceç‰ˆQwené‡‡ç”¨é»˜è®¤é…ç½®ï¼Œæœªå®‰è£…ï¼Œæœªå¯ç”¨FlashAttentionç›¸å…³æ¨¡å—
- æ³¨ï¼šint8 smooth quantç¼–è¯‘æ—¶æ‰“å¼€äº†`--per_token --per_channel`é€‰é¡¹
- æµ‹è¯•ç»“æœï¼ˆè¯¥ç»“æœç”±`qwen/benchmark.py`ç”Ÿæˆï¼‰
1. æœ€å¤§è¾“å…¥é•¿åº¦ï¼š2048ï¼Œ æœ€å¤§æ–°å¢é•¿åº¦ï¼š2048ï¼Œnum-prompts=100, beam=1, seed=0

| æµ‹è¯•å¹³å°     | åŠ é€Ÿæ–¹å¼                  | max_batch_size | ååé€Ÿåº¦ï¼ˆrequests/sï¼‰ | ç”Ÿæˆé€Ÿåº¦ï¼ˆtokens/sï¼‰ | åååŠ é€Ÿæ¯” | ç”ŸæˆåŠ é€Ÿæ¯” |
| ------------ | ------------------------- | -------------- | ---------------------- | -------------------- | ---------- | ---------- |
| HuggingFace  | dtype: bf16               | 1              | 0.12                   | 60.45                | 1          | 1          |
| HuggingFace  | dtype: bf16               | 2              | OOM                    | OOM                  | /          | /          |
|              |                           |                |                        |                      |            |            |
| TensorRT-LLM | dtype: fp16               | 1              | 0.18                   | 88.73                | 1.50       | 1.46       |
| TensorRT-LLM | dtype: fp16               | 2              | 0.22                   | 115.23               | 1.83       | 1.90       |
| TensorRT-LLM | dtype: fp16               | 3              | OOM                    | OOM                  | /          | /          |
|              |                           |                |                        |                      |            |            |
| TensorRT-LLM | dtype: int8 (weight only) | 1              | 0.30                   | 147.38               | 2.50       | 2.44       |
| TensorRT-LLM | dtype: int8 (weight only) | 2              | 0.31                   | 162.60               | 2.58       | 2.69       |
| TensorRT-LLM | dtype: int8 (weight only) | 3              | 0.34                   | 185.65               | 2.83       | 3.07       |
| TensorRT-LLM | dtype: int8 (weight only) | 4              | 0.36                   | 198.46               | 3.00       | 3.28       |
| TensorRT-LLM | dtype: int8 (weight only) | 5              | OOM                    | OOM                  | /          | /          |
|              |                           |                |                        |                      |            |            |
| TensorRT-LLM | dtype: int4 (weight only) | 1              | 0.49                   | 239.98               | 4.08       | 3.97       |
| TensorRT-LLM | dtype: int4 (weight only) | 2              | 0.47                   | 242.10               | 3.92       | 4.00       |
| TensorRT-LLM | dtype: int4 (weight only) | 3              | 0.50                   | 269.89               | 4.17       | 4.46       |
| TensorRT-LLM | dtype: int4 (weight only) | 4              | 0.50                   | 273.29               | 4.17       | 4.52       |
| TensorRT-LLM | dtype: int4 (weight only) | 5              | 0.49                   | 268.98               | 4.08       | 4.45       |
| TensorRT-LLM | dtype: int4 (weight only) | 6              | **0.51**               | **283.53**           | **4.25**   | **4.69**   |
| TensorRT-LLM | dtype: int4 (weight only) | 7              | OOM                    | OOM                  | /          | /          |
|              |                            |                |                        |                      |            |            |
| TensorRT-LLM | dtype: int8 (smooth quant) | 1              | 0.29                   | 146.98               | 2.42       | 2.43       |
| TensorRT-LLM | dtype: int8 (smooth quant) | 2              | 0.35                   | 184.63               | 2.92       | 3.05       |
| TensorRT-LLM | dtype: int8 (smooth quant) | 3              | 0.38                   | 209.48               | 3.17       | 3.47       |
| TensorRT-LLM | dtype: int8 (smooth quant) | 4              | 0.42                   | 227.64               | 3.5        | 3.77       |
| TensorRT-LLM | dtype: int8 (smooth quant) | 5              | OOM                    | OOM                  | /          | /          |

2. æœ€å¤§è¾“å…¥é•¿åº¦ï¼š1024ï¼Œ æœ€å¤§æ–°å¢é•¿åº¦ï¼š1024ï¼Œnum-prompts=100, beam=1, seed=0

| æµ‹è¯•å¹³å°     | åŠ é€Ÿæ–¹å¼                  | max_batch_size | ååé‡ï¼ˆrequests/sï¼‰ | ç”Ÿæˆé€Ÿåº¦ï¼ˆtokens/sï¼‰ | åååŠ é€Ÿæ¯” | ç”ŸæˆåŠ é€Ÿæ¯” |
| ------------ | ------------------------- | -------------- | -------------------- | -------------------- | ---------- | ---------- |
| HuggingFace  | dtype: bf16               | 1              | 0.14                 | 51.48                | 1          | 1          |
| HuggingFace  | dtype: bf16               | 2              | 0.12                 | 53.87                | 0.86       | 1.05       |
| HuggingFace  | dtype: bf16               | 3              | OOM                  | OOM                  | /          | /          |
|              |                           |                |                      |                      |            |            |
| TensorRT-LLM | dtype: fp16               | 1              | 0.20                 | 74.75                | 1.43       | 1.45       |
| TensorRT-LLM | dtype: fp16               | 2              | 0.23                 | 91.80                | 1.64       | 1.70       |
| TensorRT-LLM | dtype: fp16               | 3              | 0.26                 | 108.50               | 1.86       | 2.01       |
| TensorRT-LLM | dtype: fp16               | 4              | 0.29                 | 123.58               | 2.07       | 2.29       |
| TensorRT-LLM | dtype: fp16               | 5              | 0.31                 | 136.06               | 2.21       | 2.53       |
| TensorRT-LLM | dtype: fp16               | 6              | 0.31                 | 137.69               | 2.21       | 2.56       |
| TensorRT-LLM | dtype: fp16               | 7              | OOM                  | OOM                  | /          | /          |
|              |                           |                |                      |                      |            |            |
| TensorRT-LLM | dtype: int8 (weight only) | 1              | 0.34                 | 128.52               | 2.43       | 2.39       |
| TensorRT-LLM | dtype: int8 (weight only) | 2              | 0.34                 | 139.42               | 2.43       | 2.59       |
| TensorRT-LLM | dtype: int8 (weight only) | 3              | 0.37                 | 158.25               | 2.64       | 2.94       |
| TensorRT-LLM | dtype: int8 (weight only) | 4              | 0.40                 | 175.28               | 2.86       | 3.25       |
| TensorRT-LLM | dtype: int8 (weight only) | 5              | 0.44                 | 193.93               | 3.14       | 3.60       |
| TensorRT-LLM | dtype: int8 (weight only) | 6              | 0.41                 | 184.75               | 2.93       | 3.43       |
| TensorRT-LLM | dtype: int8 (weight only) | 7              | 0.46                 | 206.81               | 3.29       | 3.84       |
| TensorRT-LLM | dtype: int8 (weight only) | 8              | 0.43                 | 195.05               | 3.07       | 3.62       |
| TensorRT-LLM | dtype: int8 (weight only) | 9              | 0.47                 | 208.96               | 3.36       | 4.06       |
| TensorRT-LLM | dtype: int8 (weight only) | 10             | 0.47                 | 214.72               | 3.36       | 4.17       |
| TensorRT-LLM | dtype: int8 (weight only) | 11             | 0.45                 | 205.00               | 3.21       | 3.98       |
| TensorRT-LLM | dtype: int8 (weight only) | 12             | OOM                  | OOM                  | /          | /          |
|              |                           |                |                      |                      |            |            |
| TensorRT-LLM | dtype: int4 (weight only) | 1              | 0.59                 | 217.27               | 4.21       | 4.22       |
| TensorRT-LLM | dtype: int4 (weight only) | 2              | 0.54                 | 217.12               | 3.86       | 4.22       |
| TensorRT-LLM | dtype: int4 (weight only) | 3              | 0.55                 | 235.90               | 3.93       | 4.58       |
| TensorRT-LLM | dtype: int4 (weight only) | 4              | 0.55                 | 240.24               | 3.93       | 4.67       |
| TensorRT-LLM | dtype: int4 (weight only) | 5              | 0.61                 | 267.75               | 4.36       | 5.20       |
| TensorRT-LLM | dtype: int4 (weight only) | 6              | 0.61                 | 271.05               | 4.36       | 5.27       |
| TensorRT-LLM | dtype: int4 (weight only) | 7              | 0.60                 | 271.51               | 4.29       | 5.27       |
| TensorRT-LLM | dtype: int4 (weight only) | 8              | 0.60                 | 273.13               | 4.29       | 5.31       |
| TensorRT-LLM | dtype: int4 (weight only) | 9              | 0.63                 | 279.14               | 4.5        | 5.42       |
| TensorRT-LLM | dtype: int4 (weight only) | 10             | **0.64**             | **286.16**           | **4.57**   | **5.56**   |
| TensorRT-LLM | dtype: int4 (weight only) | 11             | 0.58                 | 266.91               | 4.14       | 5.18       |
| TensorRT-LLM | dtype: int4 (weight only) | 12             | 0.56                 | 254.73               | 4.00       | 4.95       |
| TensorRT-LLM | dtype: int4 (weight only) | 13             | 0.56                 | 256.27               | 4.00       | 4.98       |
| TensorRT-LLM | dtype: int4 (weight only) | 14             | OOM                  | OOM                  | /          | /          |
|              |                            |                |                      |                      |            |            |
| TensorRT-LLM | dtype: int8 (smooth quant) | 1              | 0.36                 | 134.10               | 2.57       | 2.6        |
| TensorRT-LLM | dtype: int8 (smooth quant) | 2              | 0.40                 | 161.98               | 2.86       | 3.15       |
| TensorRT-LLM | dtype: int8 (smooth quant) | 3              | 0.45                 | 185.56               | 3.21       | 3.6        |
| TensorRT-LLM | dtype: int8 (smooth quant) | 4              | 0.50                 | 214.51               | 3.57       | 4.17       |
| TensorRT-LLM | dtype: int8 (smooth quant) | 5              | 0.56                 | 240.23               | 4.00       | 4.67       |
| TensorRT-LLM | dtype: int8 (smooth quant) | 6              | 0.53                 | 229.17               | 3.79       | 4.45       |
| TensorRT-LLM | dtype: int8 (smooth quant) | 7              | 0.53                 | 234.73               | 4.56       | 4.56       |
| TensorRT-LLM | dtype: int8 (smooth quant) | 8              | 0.55                 | 245.52               | 3.93       | 4.77       |
| TensorRT-LLM | dtype: int8 (smooth quant) | 9              | 0.56                 | 248.33               | 4.00       | 4.82       |
| TensorRT-LLM | dtype: int8 (smooth quant) | 10             | 0.58                 | 258.25               | 4.14       | 5.02       |
| TensorRT-LLM | dtype: int8 (smooth quant) | 11             | 0.55                 | 245.96               | 3.93       | 4.78       |
| TensorRT-LLM | dtype: int8 (smooth quant) | 12             | OOM                  | OOM                  | /          | /          |

### BugæŠ¥å‘Šï¼ˆå¯é€‰ï¼‰
<details><summary>ç‚¹å‡»è¿™é‡Œå±•å¼€/æŠ˜å å†…å®¹</summary>
<ul>
<li><p>æäº¤bugæ˜¯å¯¹TensorRT/TensorRT-LLMçš„å¦ä¸€ç§è´¡çŒ®ã€‚å‘ç°çš„TensorRT/TensorRT-LLMæˆ–cookbookã€æˆ–æ–‡æ¡£å’Œæ•™ç¨‹ç›¸å…³bugï¼Œè¯·æäº¤åˆ°<a href="https://github.com/NVIDIA/trt-samples-for-hackathon-cn/issues">github issues</a>ï¼Œå¹¶è¯·åœ¨è¿™é‡Œç»™å‡ºé“¾æ¥ã€‚</p>
</li>
<li><p>ç›®å‰å·²æäº¤çš„é’ˆå¯¹TensorRTçš„bugé“¾æ¥ï¼ˆå·²ç”±å¯¼å¸ˆå¤æ ¸ç¡®å®šï¼‰ï¼š<a href="https://github.com/NVIDIA/trt-samples-for-hackathon-cn/issues/86">Bug1</a>, <a href="https://github.com/NVIDIA/trt-samples-for-hackathon-cn/issues/89">Bug2</a></p>
</li>
<li><p>å·²æäº¤ï¼Œå¾…å¤æ ¸çš„bugï¼š<a href="https://github.com/NVIDIA/trt-samples-for-hackathon-cn/issues/90">Bug3</a></p>
</li>
</ul>
</details>

### é€åˆ†é¢˜ç­”æ¡ˆ | [æ“ä½œæ­¥éª¤](./docs/SEND_POINT_README.md)
<details><summary>ç‚¹å‡»è¿™é‡Œå±•å¼€/æŠ˜å å†…å®¹</summary>
<ol>
<li>ç¬¬ä¸€é¢˜ã€‚</li>
</ol>
<ul>
<li>é¢˜ç›®å†…å®¹ï¼š</li>
</ul>
<pre><code class="language-text">è¯·åœ¨æŠ¥å‘Šä¸­å†™å‡º /root/workspace/tensorrt_llm_july-release-v1/examples/gpt/README é‡Œé¢ â€œSingle node, single GPUâ€ éƒ¨åˆ†å¦‚ä¸‹å‘½ä»¤çš„è¾“å‡ºï¼ˆ10åˆ†ï¼‰æ¨¡å‹ä¸ºgpt2-medium
python3 run.py --max_output_len=8
</code></pre>
<ul>
<li>è¾“å‡ºç»“æœ</li>
</ul>
<pre><code class="language-bash">Input: Born in north-east France, Soyer trained as a
Output:  chef and eventually became a chef at a
</code></pre>
<ol start="2">
<li>ç¬¬äºŒé¢˜ã€‚</li>
</ol>
<ul>
<li>é¢˜ç›®å†…å®¹</li>
</ul>
<pre><code class="language-text">è¯·åœ¨æŠ¥å‘Šä¸­å†™å‡º /root/workspace/tensorrt_llm_july-release-v1/examples/gpt/README é‡Œé¢ â€œSummarization using the GPT modelâ€ éƒ¨åˆ†å¦‚ä¸‹å‘½ä»¤çš„rouge åˆ†æ•°ï¼ˆ10åˆ†ï¼‰æ¨¡å‹ä¸ºgpt2-medium
python3 summarize.py --engine_dirtrt_engine/gpt2/fp16/1-gpu --test_hf --batch_size1 --test_trt_llm --hf_model_location=gpt2 --check_accuracy --tensorrt_llm_rouge1_threshold=14
</code></pre>
<ol start="2">
<li>è¾“å‡ºç»“æœ</li>
</ol>
<pre><code class="language-bash">TensorRT-LLM (total latency: 3.0498504638671875 sec)
TensorRT-LLM beam 0 result
  rouge1 : 21.869322054781037
  rouge2 : 6.258925475911645
  rougeL : 16.755771650012953
  rougeLsum : 18.68034777724496
Hugging Face (total latency: 9.381023168563843 sec)
HF beam 0 result
  rouge1 : 22.08914935260929
  rouge2 : 6.127009262128831
  rougeL : 16.982143879321
  rougeLsum : 19.04670077160925
</code></pre>
</details>
